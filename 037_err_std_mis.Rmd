# L'errore standard della misurazione 

```{r, include = FALSE}
source("_common.R")
```

Secondo @lord1968statistical, l'errore $E = X - T$ rappresenta la variabile aleatoria di primario interesse per la CTT. Infatti, poiché lo scopo della CTT è di stimare il punteggio vero di ciascun rispondente e confrontare le stime ottenute per rispondenti diversi, la grandezza dell'errore $E$ è un'informazione essenziale. La discrepanza tra il punteggio osservato e il punteggio vero può essere misurata utilizzando la deviazione standard di $E$, chiamata "errore standard della misurazione" o SEM. Pertanto, l'errore standard della misurazione è lo strumento utilizzato dalla CTT per stimare in che misura un punteggio osservato si discosta da un punteggio vero.

In questo capitolo vedremo come si può stimare $\sigma_E$.

## L'incertezza della misura 

Secondo la CTT, l'errore standard della misurazione può essere stimato utilizzando una formula che richiede la conoscenza della deviazione standard della distribuzione dei punteggi del test e dell'affidabilità del test. Se questi valori sono noti (o possono essere calcolati), allora si può ottenere una stima dell'errore standard di un particolare punteggio. Tale misura di errore è utile per comprendere quanto il punteggio osservato si discosta dal vero punteggio del soggetto.

Secondo la CTT, è possibile stimare l'errore standard della misurazione ($\sigma_E$) utilizzando l'equazione:

$$
\sigma_E = \sigma_X \sqrt{1 -\rho_{XX^\prime}},
(\#eq:err-stnd-mis)
$$ 

dove $\sigma_X$ è la deviazione standard dei punteggi ottenuti in un campione di rispondenti e $\rho_{XX^\prime}$ è il coefficiente di attendibilità. Per calcolare $\sigma_E$, si sottrae l'attendibilità del test da 1, si prende la radice quadrata della differenza e si moltiplica per la deviazione standard dei punteggi del test.

L'errore standard della misurazione si basa sull'assunzione che, se una persona facesse un gran numero di test equivalenti, i punteggi di questi test sarebbero distribuiti normalmente, con il vero punteggio della persona come media. In altre parole, possiamo immaginare che la persona completi molte versioni identiche del test, senza ricordare le risposte precedenti e in condizioni simili ogni volta. In questo scenario ipotetico, l'errore standard della misurazione sarebbe semplicemente la deviazione standard di queste misurazioni ripetute.

È importante notare che l'errore standard della misurazione $\sigma_E$ è direttamente legato all'attendibilità del test: l'errore standard della misurazione diminuisce al crescere dell'attendibilità del test. Se l'attendibilità del test è uguale a 0 $\sigma_E$ diventa uguale alla deviazione standard del punteggio osservato del test. Se l'attendibilità del test è uguale a 1 $\sigma_E$ diventa uguale a zero: se il test è
perfettamente affidabile non ci sono errori e $\sigma_E$ è uguale a
zero.

### Interpretazione

McDonald sostiene che il termine $E$ segue una *propensity distribution*, che rappresenta le fluttuazioni casuali nel tempo di un individuo che risponde al test. Queste fluttuazioni possono essere causate da fattori come l'umore, la motivazione, ecc. L'errore standard di misura fornisce una stima della deviazione standard di tali punteggi, ovvero una stima della deviazione standard dei punteggi che un singolo individuo otterrebbe nel caso di infinite somministrazioni del test (o di forme parallele del test) sotto le stesse identiche condizioni, se il punteggio vero rimanesse costante.

D'altra parte, la teoria classica dei test (CTT) presuppone che i punteggi ottenuti da un individuo in infinite somministrazioni del test nelle stesse identiche condizioni seguano una distribuzione normale centrata sul valore vero. L'errore standard di misura è quindi la stima della deviazione standard di tale distribuzione ipotetica di punteggi. Maggiore è l'errore standard di misura, maggiore è l'errore che si commette nell'utilizzo del test per valutare l'abilità latente del rispondente.

Il coefficiente di attendibilità, la varianza dell'errore e l'errore
standard della misurazione sono tutti indicatori diretti o indiretti
della precisione del test. Tuttavia, questi indici forniscono
informazioni diverse sul grado di precisione del test:

-   l'errore standard della misurazione ci consente di fare inferenze
    sulla precisione del punteggio osservato di un singolo rispondente,
    ma non è possibile assegnare tale interpretazione al coefficiente di
    attendibilità;
-   l'errore standard della misurazione è espresso nella stessa unità di
    misura del punteggio osservato, mentre la varianza di $E$ è espressa
    nei termini del quadrato del punteggio osservato;
-   l'attendibilità corrisponde ad un rapporto tra varianze e dunque è
    un numero puro (privo di unità di misura).
    


**Esempio 1.** Supponiamo che un test di intelligenza produca un punteggio medio pari a
100 con una deviazione standard di 15. Supponiamo inoltre che il test
abbia una attendibilità pari a 0.73. Si calcoli l'errore standard della
misurazione.

Applicando la formula dell'errore standard della misurazione, otteniamo 

\begin{equation}
\begin{aligned}
\sigma_E &= \sigma_X \sqrt{1 -\rho_{XX^\prime}} \notag\\
&= 15 \sqrt{1 - 0.73} \notag\\
&= 7.79.\notag
\end{aligned}
\end{equation}

Il valore di 7.79 significa che, se immaginiamo di somministrare molte volte il test ad un rispondente, sotto le stesse identiche condizioni, ci aspettiamo che i valori
ottenuti differiscano tra loro, in media, di circa 8 punti tra le
successive somministrazioni del test. Inoltre, se immaginiamo di
somministrare molte volte il test ad un rispondente, sotto le stesse
identiche condizioni, ci aspettiamo che il 95% dei punteggi così
ottenuti sia compreso nell'intervallo

$$
\text{punteggio vero del rispondente} \pm 1.96 \cdot \text{errore standard della misurazione}. 
$$
Questa è una proprietà della distribuzione gaussiana.

Per il caso presente, questo intervallo è uguale a $2 \cdot 1.96 \cdot 7.79 = 30.54$ punti. 

In altre parole, ci possiamo aspettare che, nel caso di somministrazioni ripetute del test sotto le stesse identiche condizioni, i punteggi del QI di un singolo rispondente varino tra loro all'interno di un intervallo di 30 punti. Ciò significa
che, se il test avesse un'attendibilità pari a 0.73, e se la deviazione
standard dei punteggi del test nella popolazione fosse pari a 15, la
somministrazione di un tale test ad un singolo individuo sarebbe di
scarsa utilità, a causa dell'enorme errore di misurazione. Per fare un
confronto con i dati di questo esempio, la Full Scale IQ (FSIQ) della
WAIS-IV [@wechsler2008wechsler] ha un'attendibilità split-half pari a 0.98, con
errore standard di misurazione pari a 2.16.

Si noti che l'errore standard della misurazione può essere calcolato con la funzione `SE.Means()` del pacchetto `psychometric`.

```{r}
suppressWarnings(suppressMessages(library("psychometric")))

SE.Meas(15, .73)
```

**Esempio 2.** Continuando con l'esempio precedente, per gli ipotetici dati riportati
sopra, poniamoci ora la seguente domanda: qual è la probabilità che un
rispondente ottenga un punteggio minore o uguale a 116 nel test, se il
suo punteggio vero è uguale a 120?

Il problema si risolve rendendosi conto che i punteggi del
rispondente si distribuiscono normalmente attorno al punteggio vero di
120, con una deviazione standard uguale a 7.79. Dobbiamo dunque trovare
l'area sottesa alla normale $\mathcal{N}(120, 7.79)$ nell'intervallo
$[-\infty, 116]$. Utilizzando , la soluzione si trova nel modo
seguente:

```{r}
pnorm(116, 120, 7.79)
```

Se la variabile aleatorie corrispondente al punteggio osservato segue
una distribuzione $\mathcal{N}(120, 7.79)$, la probabilità che il
rispondente ottenga un punteggio minore o uguale a 116 è dunque uguale a
0.30.


**Esempio 3.** Sempre per l'esempio discusso, poniamoci ora la seguente domanda: quale intervallo di valori centrato sul punteggio vero contiene, con una probabilità di 0.95, i punteggi che il rispondente otterrebbe in ipotetiche somministrazioni ripetute del
test sotto le stesse identiche condizioni?

Dobbiamo trovare i quantili della distribuzione $\mathcal{N}(120, 7.79)$ a cui sono associate le probabilità di 0.025 e 0.975. La soluzione è dunque data da:

```{r}
qnorm(c(.025, .975), 120, 7.79)
```

L'intervallo cercato è dunque $[104.7, 135.3]$.


**Esempio 4.** Calcoliamo ora l'errore standard di misurazione utilizzando un set di dati grezzi.

Iniziamo a definire una funzione che ritorna il coefficiente di attendibilità $\alpha$ di Cronbach (questo argomento sarà discusso in un capitolo successivo).

```{r}
coeff.alpha <- function(responses){
  # Get number of items (N) and individuals
  n.items <- ncol(responses)
  n.persons <- nrow(responses)
  # Get individual total scores
  x <- rowSums(responses)
  # Get observed-score variance of whole test (X)
  var.x <- var(x)*(n.persons-1)/n.persons
  # Get observed-score variance of each item (Y_j)
  var.y <- numeric(n.items)
  for(i in 1:n.items){
    var.y[i] <- var(responses[,i])*(n.persons-1)/n.persons
  }
  # Apply the alpha formula
  alpha <- (n.items/(n.items-1))*(1 - sum(var.y)/var.x)
  return(alpha)
}
```

Definiamo una funzione per calcolare l'errore standard di misurazione usando la formula che abbiamo discusso in questo capitolo.

```{r}
se.m <- function(responses, rel.est = "alpha") {
  # The number of subjects
  n.persons <- nrow(responses)
  # Get the total score and its standard deviation
  total <- rowSums(responses)
  sd.x <- sqrt(var(total) * (n.persons - 1) / n.persons)
  if (rel.est == "alpha") {
    rel <- coeff.alpha(responses)
  } else {
    error("rel.est must be either alpha")
  }
  se.m <- sd.x * sqrt(1 - rel)
  return(se.m)
}
```

Leggiamo ora un set di dati dal pacchetto `hemp`. Per l'installazione di `hemp` si procede nel modo seguente.

```{r, eval = FALSE}
install.packages("devtools")
library("devtools")
```

```{r, eval = FALSE}
install_github("cddesja/hemp")
```

Carichiamo `hemp` e leggiamo i dati. 

```{r}
library("hemp")
data(SAPA)
head(SAPA)
```

Useremo qui i dati SAPA. Il set di dati SAPA è costituito da 1525 risposte a un test di abilità a scelta multipla di 16 item tratti da un progetto di valutazione della personalità  chiamato *Synthetic Aperture Personality Assessment* (SAPA). Gli item misurano il ragionamento di base, la manipolazione di serie alfanumeriche, il ragionamento con matrici e la capacità di rotazione mentale.

Iniziamo con il verificare se ci sono dati mancanti.

```{r}
num_miss(SAPA)
```

Dato che ci sono solo pochi dati mancanti, rimuoviamo tutte le righe che contengono dati mancanti.

```{r}
df <- na.omit(SAPA)
```

Possiamo ora usare la funzione `se.m()` che abbiamo definito sopra.

```{r}
se.m(df, "alpha")
```


### Simulazione

Torniamo ora alla simulazione precedente in cui abbiamo messo in relazione il modello della CTT con il modello di regressione lineare. In base a tale simulazione, poniamoci lo scopo di chiarire il significato dell'errore standard della misurazione.

Impostiamo la simulazione come abbiamo fatto in precedenza. Chiamiamo $X$ il valore osservato in un test. Per la CTT, il punteggio osservato $X$ è costituito da due componenti, la componente vera $T$ e la componente d'errore $E$. Si suppone che gli errori siano gaussiani e incorrelati con la componente vera. Immaginiamo di somministrare 200 volte il test ad un individuo sotto le stesse identiche condizioni.

```{r}
library("MASS")
library("arm")
set.seed(123)
n <- 200
Sigma <- matrix(
    c(11, 0, 
       0, 4), byrow = TRUE, ncol = 2)
mu <- c(100, 0)
Y <- mvrnorm(n, mu, Sigma, empirical=TRUE)
T <- Y[, 1]
E <- Y[, 2]
```

Verifichiamo l'incorrelazione tra $T$ ed $E$:

```{r}
cor(T, E)
```

I valori ottenuti sono la somma del valore vero e della componente
d'errore:

```{r}
X <- T + E
```

Per questi dati, il coefficiente di attendibilità è uguale a:

```{r}
rxx <- cor(X, T)^2
rxx
```

Possiamo ora calcolare l'errore standard della misurazione utilizzando
la \@ref(eq:err-stnd-mis):

```{r}
sd(X) * sqrt(1 - rxx)
```

Si noti che tale valore non è altro che la deviazione standard degli
errori della misurazione:

```{r}
sd(E)
```

Verifichiamo ora quanto segue: nei termini del modello di regressione $X = 0 + 1 \cdot T + E$, l'errore standard della misurazione della CTT è uguale all'errore standard
della regressione:

```{r}
fm <- lm(formula = X ~ T)
summary(fm)
```

## Dimostrazione

Poniamoci ora il problema di derivare la formula dell'errore standard
della misurazione. Per derivare la formula $\sigma_E = \sigma_X \sqrt{1 -\rho_{XX^\prime}}$ sono necessari due passi: prima dobbiamo trovare la varianza del punteggio vero; poi dobbiamo esprimere il punteggio osservato come la somma della varianza del punteggio vero e la varianza dell'errore.

In base alla definizione del coefficiente di attendibilità $\rho_{XX^\prime} = \frac{\sigma^2_T}{\sigma^2_X}$ possiamo scrivere $\sigma^2_T = \rho_{XX^\prime} \sigma^2_X$, dove $X$ e $X^\prime$ sono due forme parallele di un test. Ricordiamo che misurazioni parallele hanno le seguenti proprietà: $\mathbb{E}(X) = \mathbb{E}(X^\prime)$ e $\mathbb{V}(X) = \mathbb{V}(X^\prime)$. Dato che $\sigma_{X}=\sigma_{X^\prime}$, l'equazione precedente diventa $\sigma^2_T = \rho_{XX^\prime} \sigma_X\sigma_{X^\prime}.$ Utilizzando la definizione della covarianza tra $X$ e $X^\prime$, ovvero, $\sigma_{XX^\prime}=\rho_{XX^\prime}\sigma_X\sigma_{X^\prime}$, possiamo concludere che la varianza del punteggio vero è uguale alla covarianza tra due misurazioni parallele:

$$
\sigma^2_T =  \sigma_{XX^\prime}.
$$

Essendo l'attendibilità del test il rapporto tra la varianza del punteggio vero e la varianza del punteggio osservato, ed essendo che la varianza del punteggio vero
uguale alla covarianza tra due misurazioni parallele, possiamo
concludere che l'attendibilità aumenta all'aumentare della covarianza
media tra gli item del test. Si noti come questo importante risultato
della CTT dipenda dall'ipotesi di omogeneità delle varianze degli item
del test.

Calcoliamo ora la varianza di $E$. La varianza del punteggio osservato è
uguale a $\sigma^2_X = \sigma^2_T + \sigma^2_E.$ Sulla base della
definizione di attendibilità $\sigma^2_T = \rho_{XX^\prime} \sigma^2_X$, la
varianza del punteggio osservato si può scrivere come
$\sigma^2_X =\rho_{XX^\prime} \sigma^2_X + \sigma^2_E$, da cui

\begin{equation}
\begin{aligned}
\sigma^2_E &= \sigma^2_X - \sigma^2_X\rho_{XX^\prime}\notag\\
&= \sigma^2_X (1 -\rho_{XX^\prime}).
\end{aligned}
\end{equation}

La varianza degli errori della misurazione $\sigma^2_E = \sigma^2_X (1 -\rho_{XX^\prime})$ è dunque uguale al prodotto di due fattori: il primo fattore è la varianza del punteggio osservato; il secondo fattore è uguale a uno meno la
correlazione tra due forme parallele del test. Possiamo così calcolare
una quantità incognita, $\sigma^2_E$, nei termini di due quantità
osservabili, $\sigma^2_X$ e $\rho_{XX^\prime}$.


## Intervallo di confidenza per il punteggio vero e $\sigma_E$

Uno degli usi che vengono fatti dell'errore standard della misurazione è
quello di costruire, con essi, gli intervalli di confidenza per il
punteggio vero. Tale uso, però, non è corretto [@charter1996revisiting].
Gli intervalli di confidenza costruiti usando l'errore standard della
misurazione vengono talvolta incorrettamente interpretati in modo tale
da suggerire che l'intervallo di confidenza al $(1 - \alpha)\%$
identifica una gamma di valori, _centrata sul valore osservato_, entro
il quale cadono i punteggi veri del test nel $(1 - \alpha)\%$ di
ipotetiche somministrazioni ripetute del test. Ma le cose non stanno
così. In realtà, come abbiamo detto sopra, l'errore standard della
misurazione è la deviazione standard, calcolata rispetto al valore
vero, di ipotetiche misurazioni ripetute dello stesso test. Si può
ribadire questo concetto nel modo seguente: "In spite of @dudek1979continuing's reminder that the SEM should not be used to construct confidence intervals, many test manuals, computer-scoring programs, and texts in psychology and education continue to do so. Because authors of many textbooks and manuals make these errors, it is understandable that those who learned from and look to these sources for guidance also make these errors. In summary, the SEM should not be used to construct confidence intervals for test scores" (p. 1141). Sembra piuttosto chiaro.

## Conclusioni

Le stime di affidabilità sono uno strumento utile nell'ambito della teoria classica dei test (CTT) per valutare la coerenza dei test. Tuttavia, quando si prendono decisioni importanti sul superamento o meno di un esame, ad esempio, è più utile fare ricorso all'errore standard di misurazione (SEM) per valutare la coerenza di una serie di punteggi del test. Il SEM fornisce una stima quantitativa del grado di variazione dei punteggi del test dovuto ad errori di misurazione all'interno di un insieme di punteggi.

Il SEM è una stima dell'errore medio nei punteggi di tutti gli esaminati che hanno sostenuto il test. Utilizzando il SEM, possiamo calcolare fino a che punto i punteggi degli esaminati possono variare solo per caso con una certa probabilità. In particolare, possiamo prevedere che l'errore può far variare i punteggi degli esaminati all'interno di una banda di più o meno un SEM con una precisione del 68% (sulla base delle percentuali previste sotto la distribuzione normale dei punteggi dei test). Ad esempio, se il punteggio vero di un candidato è 65 e il SEM è di 2, possiamo stimare che i suoi punteggi potrebbero variare casualmente tra 63 e 67 punti (65 – 2 = 63; 65 + 2 = 67) con una precisione del 68% se dovesse sostenere il test più volte. Se vogliamo essere ancora più sicuri nella previsione dei suoi punteggi in somministrazioni ripetute, possiamo utilizzare due SEM (2 + 2 = 4) e affermare che i suoi punteggi potrebbero variare solo casualmente tra 61 e 69 punti (65 – 4 = 61; 65 + 4 = 69) con una precisione del 95%.

Il SEM indica quanto i punteggi di un test possono fluttuare casualmente se lo stesso test viene ripetuto più volte dagli stessi esaminati. Un SEM di 2 punti indica che ci si può aspettare fluttuazioni relativamente basse nei punteggi, mentre un SEM di 15 punti indica fluttuazioni maggiori. In generale, più il SEM è piccolo, più stretta sarà la banda di fluttuazioni casuali, ovvero la differenza tra i punteggi veri degli esaminati e quelli osservati. Questo significa che, se il SEM è piccolo, i punteggi rappresenteranno in modo più coerente le vere abilità degli esaminati. Alcuni psicologi preferiscono utilizzare il SEM rispetto alle stime di affidabilità del test, in quanto il SEM rappresenta una banda di punteggio più facilmente interpretabile rispetto alle stime di affidabilità, che possono essere più astratte o basate sulla stabilità temporale del test.

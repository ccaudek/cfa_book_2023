# La stima del punteggio vero 

```{r, include = FALSE}
source("_common.R")
```

Uno degli scopi principali della valutazione psicologica è quello di
stimare il punteggio vero del rispondente. Il punteggio osservato $X$
differisce dal punteggio vero $T$ a causa della presenza dell'errore
della misurazione: $X = T + E$. Poniamoci ora il problema di utilizzare
i concetti della Teoria Classica per stimare il punteggio vero di un
rispondente utilizzando il suo punteggio osservato e l'attendibilità del
test. Questa stima è utile soprattutto quando è necessario costruire un
intervallo di confidenza per il punteggio vero del rispondente.

Per costruire l'intervallo di confidenza del punteggio vero dobbiamo
utilizzare due quantità:

-   una stima del punteggio vero, 
-   l'errore standard della stima (ovvero, una stima della deviazione
    standard della distribuzione delle stime del punteggio vero che si
    otterrebbe se il test venisse somministrato infinite volte sotto le
    stesse condizioni).

Iniziamo con il problema della stima del punteggio vero.

## Il paradosso di Kelley

<!-- Nella sua monografia del 1954, "Clinical versus statistical prediction: -->
<!-- A theoretical analysis and a review of the evidence", Paul Meehl suscitò -->
<!-- un grande scalpore con una convincente dimostrazione del fatto che -->
<!-- metodi meccanici di combinazione dei dati, come ad esempio la -->
<!-- regressione multipla, sono in grado di fornire delle predizioni migliori -->
<!-- di quanto sia in grado di fare la diagnosi clinica eseguita da esperti. -->
<!-- L'enorme quantità di letteratura che è stata prodotta in seguito a tale -->
<!-- contributo ha fornito forti e univoche evidenze a sostegno di questa -->
<!-- osservazione. -->

<!-- È interessante notare che Robyn Dawes (2005) ha pubblicato un articolo -->
<!-- su *Journal of Clinical Psychology* (61, 1245--1255) dal titolo -->
<!-- seguente: "The ethical implications of Paul Meehl's Work on comparing -->
<!-- clinical versus actuarial prediction methods". L'argomento principale -->
<!-- sostenuto da Dawes è che, date le evidenze molto convincenti che sono -->
<!-- disponibili, non è etico usare il giudizio clinico in preferenza all'uso -->
<!-- di modelli statistici di previsione. Citiamo dall'abstract: -->

<!-- > Whenever statistical prediction rules [...] are available for making a relevant prediction, they should be used in preference to intuition. [...] Providing service that assumes that clinicians "can do better" simply based on self-confidence or plausibility in the absence of evidence that they can actually do so is simply unethical. -->

<!-- Sulla base di quanto detto sopra, e in riferimento ai nostri scopi -->
<!-- presenti, si pone dunque il problema di capire come sia possibile -->
<!-- utilizzare il modello di regressione per ottenere una stima del -->
<!-- punteggio vero di un rispondente. A questo proposito si deve notare che -->
<!-- è necessario tenere in considerazione il fatto che le nostre variabili -->
<!-- indipendenti sono corrotte dall'errore di misurazione, mentre il modello -->
<!-- di regressione tradizionale presuppone che le variabili indipendenti -->
<!-- siano misurate senza errori. Le considerazioni seguenti sono state -->
<!-- proposte da Kelly negli anni '20. -->

Negli anni '20, Kelly ha dimostrato come sia possibile stimare il punteggio vero del rispondente utilizzando il modello di regressione. La formula di Kelley si basa sull'equivalenza algebrica secondo cui l'attendibilità è uguale al quadrato del coefficiente di correlazione tra i punteggi osservati e i punteggi veri. Quindi, sulla base della formula di Kelley, il punteggio vero di un rispondente può essere stimato nel seguente modo:

$$
\hat{T} = \mu_x + \rho  (X - \mu_x),
(\#eq:true-score)
$$ 
laddove $X$ è il punteggio osservato, $\mu_x$ è la media dei punteggi ottenuti da tutti i rispondenti di un campione e $\rho$ è l'attendibilità del test.

Quando l'attendibilità è perfetta ($\rho = 1$), il punteggio vero è
uguale al punteggio osservato. Quando l'attendibilità è zero (tutta la
varianza è dovuta all'errore della misurazione), allora la stima
migliore del punteggio vero è data dalla media del campione. Quando
$0 < \rho < 1$, la stima del punteggio vero corrisponde ad un valore che
si discosta dal punteggio osservato nella direzione della media del
campione. La stima del punteggio vero, dunque, esibisce la proprietà
della regressione verso la media del punteggio osservato, in funzione
dell'attendibilità del test.

La formula del punteggio vero \@ref(eq:true-score) può essere spiegata come segue: per stimare il punteggio vero di un rispondente, si parte dalla media della distribuzione della popolazione dei rispondenti e si si sposta in direzione del punteggio osservato. Tuttavia, il valore del punteggio osservato non viene raggiunto, ma la quantità di spostamento è proporzionale all'attendibilità. Ciò significa che, a seconda della dimensione di $\rho$, la stima del punteggio vero dell'individuo dipende anche dalla sua posizione relativa al gruppo di appartenenza. Se l'individuo si trova al di sotto della media del gruppo, la stima del punteggio vero sarà spostata verso l'alto e viceversa. Questo effetto è noto come il "paradosso di Kelley".

È importante sottolineare che l'interpretazione precedente evidenzia una contraddizione tra la formula di Kelley e la nozione intuitiva secondo cui il punteggio osservato può essere utilizzato come stima del punteggio vero (ovvero $\hat{T} = X$). Questo ragionamento sarebbe corretto solo se l'attendibilità del test fosse perfetta ($\rho = 1$). Al contrario, quando $\rho = 0$, la formula di Kelley suggerisce di utilizzare la media dei punteggi osservati come stima del punteggio vero, il che equivale ad affermare che il punteggio osservato non ha alcuna utilità. Tuttavia, è altamente improbabile che $\rho = 0$ nella pratica. Invece, se $\rho$ si trova tra 0 e 1, la stima del punteggio vero sarà compresa tra il punteggio osservato e la media della popolazione. Per comprendere cosa questa stima rappresenti, possiamo citare Kelley (1947), che ha osservato:

> This is an interesting equation in that it expresses the estimate of true ability as the weighted sum of two separate estimates, -- one based upon the individual's observed score, $X_1$ ($X$ nella notazione corrente) and the other based upon the mean of the group to which he belongs, $M_1$ ($\mu_x$ nella notazione corrente). If the test is
highly reliable, much weight is given to the test score and little to
the group mean, and vice versa.


::: {.proof}
Per comprendere l'equazione di Kelley, dobbiamo partire dal modello di regressione lineare semplice che mette in relazione il punteggio osservato $X$ con il punteggio vero. Abbiamo visto in precedenza il modello di regressione che mette in relazione il punteggio osservato, $X = 0 + 1 \cdot T + E$. In questo caso, però, il problema è diverso, in quanto noi vogliamo *predire* il punteggio vero sulla base del punteggio
osservato per mezzo di un modello di regressione (Nunnally, 1978).

Avendo quale scopo quello di "predire" il punteggio vero $T$ sulla base
del punteggio osservato $X$, il modello di regressione diventa

$$
T = \alpha + \beta X + \varepsilon.
$$ 

Se esprimiamo le variabili come deviazioni dalla media, $x = X - \bar{X}$ e $\tau = T - \mathbb{E}(T)$, allora l'intercetta diventa uguale a zero e il modello diventa
$\tau = \beta x + \varepsilon$, ovvero $\hat{\tau} = \beta x.$ Il
problema è quello di calcolare il coefficiente $\beta$.

Nel modello $\hat{\tau} = \beta x$, la pendenza della retta di
regressione è uguale a $\beta = \frac{\sigma_{\tau x}}{\sigma^2_x}$.
Possiamo dunque scrivere il modello di regressione nel modo seguente:

\begin{equation}
\hat{\tau} = \frac{\sigma_{\tau x}}{\sigma^2_x} x.
(\#eq:hat-t-1)
\end{equation}

La correlazione tra $x$ (o $X$) e $\tau$ (o $T$) è uguale a $\rho_{\tau x} = \frac{\sigma_{\tau x}}{\sigma_x \sigma_{\tau}}$. Dunque $\sigma_{\tau x} = \rho_{\tau x}\sigma_x \sigma_{\tau}$ e l'equazione precedente diventa 

$$
\begin{equation}
\begin{aligned}
\hat{\tau} &= \frac{\sigma_{TX}}{\sigma^2_X} X  \notag\\
&= \frac{\rho_{\tau x}\sigma_x \sigma_{\tau}}{\sigma^2_x} x \notag\\
&= \rho_{\tau x}\frac{\sigma_{\tau}}{\sigma_x} x. \notag
\end{aligned}
\end{equation}
$$

In base alla definizione di attendibilità, la varianza del punteggio vero è
$\sigma^2_{\tau} = \sigma^2_x \rho_{xx^\prime}$. Dunque, la deviazione
standard del punteggio vero diventa
$\sigma_{\tau} = \sigma_x \sqrt{\rho_{xx^\prime}}$. Sostituendo questo
risultato nell'equazione precedente otteniamo 

$$
\begin{equation}
\begin{aligned}
\hat{\tau} &= \rho_{\tau x}\frac{\sigma_x \sqrt{\rho_{xx^\prime}}}{\sigma_x} x
\notag\\
&=  \rho_{\tau x}  \sqrt{\rho_{xx^\prime}} x. \notag
\end{aligned}
\end{equation}
$$

In precedenza abbiamo visto che $\rho^2_{\tau x} = \rho_{xx^\prime}$, dunque

$$
\begin{equation}
\begin{aligned}
\hat{\tau} &= \rho_{\tau x} \sqrt{\rho_{xx^\prime}} x \notag\\
        &= \sqrt{\rho_{xx^\prime}} \sqrt{\rho_{xx^\prime}} x \notag\\
        &= \rho_{xx^\prime} x.\notag
\end{aligned}
\end{equation}
$$

In conclusione, una stima del punteggio vero si ottiene moltiplicando il punteggio osservato, espresso come deviazione dalla media, per il coefficiente di attendibilità.

Riscriviamo ora la formula appena ottenuta nei termini del punteggio grezzo $X$ (non in termini di deviazioni dalla media. Per fare ciò, sommiamo $\bar{X}$ così da ottenere

$$
\hat{T} = \rho_{XX^\prime} (X - \bar{X}) + \bar{X}, 
$$ 

laddove $\hat{T}^\prime$ è la stima del punteggio vero grezzo. Sviluppando otteniamo

$$
\begin{equation}
\begin{aligned}
\hat{T} &= \rho_{XX^\prime} (X - \bar{X}) + \bar{X}\notag\\
 &=  X\rho_{XX^\prime}  - \bar{X} \rho_{XX^\prime} + \bar{X}\notag\\
&= \bar{X} (1 - \rho_{XX^\prime}) + X\rho_{XX^\prime}\notag\\
&= \bar{X} - \bar{X}\rho_{XX'} + X\rho_{XX^\prime}\notag\\
&= \bar{X} + \rho_{XX'} (X - \bar{X}).\notag
\end{aligned}
\end{equation}
$$

Per i dati campionari, la formula diventa:

$$
\hat{T} = \bar{X} + r_{XX^\prime}  (X - \bar{X}),
$$ 

dove $X$ è il punteggio (grezzo) osservato, $\bar{X}$ è la media dei punteggi
osservati di un campione di rispondenti e $r_{XX^\prime}$ è il coefficiente di
attendibilità.
:::

:::{.exercise}
Posto un coefficiente di attendibilità pari a 0.80 e una media del test pari a $\bar{X} = 100$, si trovi una stima del punteggio vero per un rispondente con un punteggio osservato uguale a $X$ = 115.

La stima del punteggio vero $\hat{T}$ è uguale a 

$$
\begin{equation}
\begin{aligned}
\hat{T} &= \bar{X} + r_{XX^\prime}  (X - \bar{X})\notag\\
&= 100 + 0.80 \cdot (115 - 100) = 112.
\end{aligned}
\end{equation}
$$
In alternativa, possiamo usare la funzione `Est.true` del pacchetto `psychometric`.

```{r}
suppressWarnings(suppressMessages(library("psychometric")))

Est.true(115, 100, .8)
```
:::

## L'errore standard della stima

Il modello di regressione di Kelley non solo ci permette di ottenere una stima del punteggio vero a partire dal punteggio osservato, ma ci fornisce anche una misura di precisione di tale stima: l'*errore standard della stima*.

Immaginiamo di poter somministrare il test ad un rispondente più volte, in condizioni identiche, e di ottenere in ogni somministrazione una stima del valore vero $\hat{T}$. A causa dell'errore di misurazione, il punteggio osservato varierà in ogni somministrazione del test, e quindi anche la stima di $\hat{T}$ varierà. La deviazione standard di queste stime ipotetiche di $\hat{T}$ è chiamata *errore standard della stima*, indicato con $\sigma_{\hat{T}}$.

Calcolare l'errore standard della stima è importante poiché ci dà un'indicazione della precisione della stima del punteggio vero. Più piccolo è l'errore standard della stima, più precisa sarà la stima del punteggio vero. L'errore standard della stima si calcola con la formula seguente:

$$
\begin{equation}
\sigma_{\hat{T}} = \sigma_X \sqrt{\rho_{XX^\prime} (1 -\rho_{XX^\prime})}.
(\#eq:std-err-estimate)
\end{equation}
$$

::: {.proof}
Per ricavare la \@ref(eq:std-err-estimate) si definisce $\varepsilon$ l'errore
che si commette quando si stima il punteggio vero $\hat{T}$ con il
punteggio osservato $T$ [si veda @lord1968statistical]:

$$
\varepsilon = T - \hat{T}.
$$ 

Si presti attenzione alla notazione: $E = X - T$ indica l'errore della misurazione, ovvero la differenza tra il punteggio osservato e il punteggio vero. Invece
$\varepsilon = T - \hat{T}$ indica la differenza tra il punteggio vero e
la stima del punteggio vero. 

Avendo che $\hat{T} = \bar{X} + \rho_{XX^\prime} (X - \bar{X})$, la varianza di $\varepsilon = T - \hat{T}$ si può scrivere come 

$$
\begin{equation}
\begin{aligned}
\mathbb{V}(\varepsilon) &=  \mathbb{V}(T - \hat{T})\notag\\
&= \mathbb{V}(T - \bar{X} - \rho_{XX^\prime} X + \rho_{XX^\prime}\bar{X}).
\end{aligned}
\end{equation}
$$

Dato che la varianza di una variabile aleatoria non cambia sommando a
tale variabile una costante, dobbiamo semplicemente calcolare

$$
\begin{equation}
\mathbb{V}(\varepsilon) = \mathbb{V}(T - \rho_{XX^\prime}X).\notag
\end{equation}
$$

Dobbiamo trovare la varianza della somma di due variabili aleatorie, una delle
quali moltiplicata per una costante. Dunque: 

$$
\mathbb{V}(\varepsilon) = \mathbb{V}(T) + \rho_{XX^\prime}^2 \mathbb{V}(X) - 2 \rho_{XX^\prime} \mbox{Cov}(X,T),
$$

ovvero, semplificando la notazione, 

$$
\begin{equation}
\sigma^2_{\varepsilon} = \sigma^2_T + \rho_{XX^\prime}^2 \sigma^2_X - 2  \rho_{XX^\prime} \sigma_{XT}.\notag
\end{equation}
$$

La quantità $\rho_{XX^\prime}$ è il coefficiente di attendibilità. Quindi

$$
\begin{equation}
\sigma^2_{\varepsilon} = \sigma^2_T + \left(\frac{\sigma_T^2}{\sigma_X^2}\right)^2 \sigma^2_X - 2  \frac{\sigma_T^2}{\sigma_X^2} \sigma_{XT}.\notag
\end{equation}
$$

Semplificando otteniamo 

$$
\begin{equation}
\begin{aligned}
\sigma^2_{\varepsilon} &= \sigma^2_T + \frac{\sigma_T^4}{\sigma_X^4}
\sigma^2_X - 2  \frac{\sigma_T^2}{\sigma_X^2} \sigma_{XT}\notag\\ 
&= \sigma^2_T + \sigma^2_T\frac{\sigma_T^2}{\sigma_X^2} -  \sigma_T^2 2
\frac{\sigma_{XT}}{\sigma_X^2} \notag\\ 
&= \sigma^2_T \left(1 + \frac{\sigma_T^2}{\sigma_X^2} - 2
  \frac{\sigma_{XT}}{\sigma_X^2}\right).\notag 
  \end{aligned}
\end{equation}
$$
  
Dato che $\sigma_{XT}=\sigma^2_T$, l'equazione precedente diventa uguale a

$$
\begin{equation}
\begin{aligned}
\sigma^2_{\varepsilon} &= \sigma^2_T \left(1
  +\frac{\sigma_T^2}{\sigma_X^2} - 2
  \frac{\sigma_{T}^2}{\sigma_X^2}\right)\notag\\
&= \sigma^2_T \left(1 - 
  \frac{\sigma_{T}^2}{\sigma_X^2}\right).
\end{aligned}
\end{equation}
$$

L'errore standard della stima è dunque uguale a 

$$
\begin{equation}
\begin{aligned}
\sigma_{\varepsilon} 
&=\sigma_T \sqrt{1-\frac{\sigma^2_T}{\sigma^2_X}}\notag\\
&=\sigma_T \sqrt{\frac{\sigma^2_X - \sigma^2_T}{\sigma^2_X}}\notag\\
&=\frac{\sigma_T}{\sigma_X} \sqrt{\sigma^2_X - \sigma^2_T}.
\end{aligned}
\end{equation}
$$

Dato che $\sigma^2_X=\sigma^2_T+\sigma^2_E$, abbiamo 

$$
\begin{equation}
\begin{aligned}
\sigma_{\varepsilon} 
 &= \frac{\sigma_T}{\sigma_X} \sqrt{\sigma^2_E }\notag\\
&=  \frac{\sigma_T}{\sigma_X} \sigma_E \notag\\
&= \sqrt{\rho_{XX^\prime}} \sigma_E. \notag
\end{aligned}
\end{equation}
$$

Ricordando che l'errore standard della misurazione è $\sigma_E = \sigma_X \sqrt{1 - \rho_{XX^\prime}}$, possiamo scrivere

$$
\begin{equation}
\begin{aligned}
\sigma_{\varepsilon}  &= \sqrt{\rho_{XX^\prime}} \sigma_E \notag\\
&= \sqrt{\rho_{XX^\prime}} \sigma_X
\sqrt{1-\rho_{XX^\prime}} \notag\\
&= \sigma_X \sqrt{\rho_{XX^\prime} (1 - \rho_{XX^\prime})}.\notag
\end{aligned}
\end{equation}
$$
:::

\

Per dati campionari, l'errore standard della stima si calcola nel modo
seguente: 

$$
s_{\hat{T}} = s_X \sqrt{r_{XX^\prime} (1-r_{XX^\prime})},
$$ 

dove $s_X$ è deviazione standard del campione e $r_{XX^\prime}$ è il coefficiente di
attendibilità.

## Intervallo di confidenza per il punteggio vero


Siamo ora finalmente nelle condizioni di potere calcolare l'intervallo di confidenza per il punteggio vero. Conoscendo l'errore standard della stima $\sigma_{\hat{T}}$,  l'intervallo di confidenza per il punteggio vero è dato da:

$$
\hat{T} \pm z  \sigma_{\hat{T}},
$$ 

laddove $\hat{T}$ è la stima del punteggio vero e $z$ è il quantile della normale standardizzata al livello di probabilità desiderato. Se il campione è piccolo (minore di
30) è opportuno usare $t$ anziché $z$.

### Interpretazione

Notiamo che l'intervallo $\hat{T} \pm z \sigma_{\hat{T}}$ è centrato sulla
stima puntuale del valore vero e la sua ampiezza dipende sia dal livello
di confidenza desiderato (rappresentato dal quantile $z_{\frac{\alpha}{2}}$),
sia dal grado di precisione dello stimatore, misurato dall'errore standard
della stima, $\sigma_{\hat{T}} = \sigma_X \sqrt{\rho_{XX^\prime} (1 -\rho_{XX^\prime})}$.
È importante notare che l'errore standard della stima diventa sempre più grande
man mano che diminuisce l'attendibilità $\rho_{XX^\prime}$ del test.

L'intervallo di confidenza indica quanto l'imprecisione della misura influisce sull'interpretazione dei dati. Più l'intervallo di confidenza è ampio, maggiore è l'incertezza nella valutazione dei risultati. 

:::{.exercise}
@charter1996revisiting ha esaminato l'effetto della variazione dell'attendibilità del test sull'ampiezza dell'intervallo di confidenza per il punteggio vero. Utilizzando come esempio i punteggi di QI ($\mu$ = 100, $\sigma$ = 15), Charter ha immaginato di variare il coefficiente di attendibilità del test utilizzato per la misurazione del QI. I valori presi in considerazione sono 0.55, 0.65, 0.75, 0.85 e 0.95. Ad esempio, supponiamo di avere un punteggio osservato pari a QI = 120 e un coefficiente di attendibilità del test $\rho_{xx^\prime}$ pari a 0.65. In tali circostanze, la stima del punteggio vero è pari a

$$
\begin{equation}
\begin{aligned}
\hat{T} &= \bar{X} + r_{XX^\prime}  (X - \bar{X}) \notag\\
&= 100 + 0.65 (120 - 100)\notag\\
&= 113.\notag
\end{aligned}
\end{equation}
$$

L'errore standard della stima è uguale a

$$
\begin{equation}
\begin{aligned}
\sigma_{\hat{T}} &= \sigma_{X} \sqrt{r_{XX^\prime} (1 - r_{XX^\prime})} \notag\\
&= 15 \sqrt{0.65 (1 - 0.65)}\notag\\
&= 7.15.\notag
\end{aligned}
\end{equation}
$$

L'intervallo di confidenza al 95% per la stima del punteggio vero diventa pertanto uguale a 

$$
113 \pm 1.96 \cdot 7.15 = [98.98, 127.02].
$$ 

Si noti che si può calcolare l'errore standard della stima con la funzione `SE.Est()` del pacchetto `psychometric`.

```{r}
suppressWarnings(suppressMessages(library("psychometric")))

SE.Est(15, .65)
```

Inoltre, la funzione `CI.tscore()` restituisce sia la stima del punteggio vero sia l'intervallo di fiducia al livello desiderato di significatività. 

```{r}
CI.tscore(120, 100, 15, 0.65, level = 0.95)
```

:::


<!-- Lo stesso risultato si ottiene con la funzione `CI.tscore()` del -->
<!-- pacchetto `psychometric` che richiede i seguenti argomenti: il punteggio -->
<!-- osservato, la media del campione, la deviazione standard del campione e -->
<!-- l'attendibilità del test: -->

<!-- ```{r} -->
<!-- library("psychometric") -->
<!-- CI.tscore(120, 100, 15, 0.65) -->
<!-- ``` -->

## Cut-off

Gli intervalli di confidenza per il punteggio vero possono essere utilizzati per confrontare i limiti dell'intervallo con un cut-off. Ci sono tre possibili esiti: il limite inferiore dell'intervallo di confidenza è maggiore del cut-off, il limite superiore dell'intervallo è minore del cut-off, o il valore del cut-off è compreso all'interno dell'intervallo. Nel primo caso, lo psicologo può affermare, con un grado di certezza $1-\alpha$, che il valore vero del rispondente è superiore al cut-off. Nel secondo caso, lo psicologo può affermare, con un grado di certezza $1-\alpha$, che il valore vero del rispondente è inferiore al cut-off. Nel terzo caso, lo psicologo non può concludere né che il valore vero sia inferiore né che sia superiore al cut-off, con un certo grado di incertezza.

:::{.exercise}
Si considerino i punteggi del QI, per cui $\bar{X}$ = 100 e $s_X$ = 15.
Sia l'attendibilità del test $\rho_{XX^\prime}$ = 0.95. Supponiamo che il
rispondente abbia un QI = 130. Poniamo che il cut-off per ammettere il
rispondente ad un corso avanzato sia 120. Ci sono tre alternative: il
valore vero del rispondente è sicuramente maggiore di 120; il valore
vero del rispondente è sicuramente inferiore di 120; le evidenze
disponibili ci lasciano in dubbio se il punteggio vero sia maggiore o
minore di 120. Svolgiamo i calcoli per trovare l'intervallo di
confidenza al livello di certezza del 95%:

```{r}
xm <- 100
sx <- 15
rho <- .95
x <- 130
t.hat <- xm + rho * (x - xm)
t.hat
se.t <- sx * sqrt(rho * (1 - rho))
se.t
t.hat + c(1, -1) * qnorm(.025, 0, 1) * se.t
```
  
Dato che il limite inferiore dell'intervallo di confidenza è maggiore
del cut-off, lo psicologo conclude che il punteggio vero del rispondente
è maggiore di 120. Quindi, raccomanda che il rispondente sia ammesso al
corso avanzato.

Continuando con l'esempio precedente, supponiamo che l'attendibilità
del test abbia un valore simile a quello che solitamente si ottiene
empiricamente, ovvero 0.80.

```{r}
xm <- 100
sx <- 15
rho <- .8
x <- 130
t.hat <- xm + rho * (x - xm)
t.hat
se.t <- sx * sqrt(rho * (1 - rho))
se.t
t.hat + c(1, -1) * qnorm(.025, 0, 1) * se.t
```

In questo secondo esempio, l'intervallo di confidenza al 95% è $[112.24,
135.76]$ e contiene il valore del cut-off. Dunque, la decisione dello
psicologo è che non vi sono evidenze sufficienti che il vero valore del
rispondente sia superiore al cut-off. Si noti come la diminuzione
dell'attendibilità del test porta all'aumento delle dimensioni
dell'intervallo di confidenza.
:::

## Procedure alternative

Non vi è un unico modo per costruire gli intervalli di confidenza per il
punteggio vero. Charter e Feldt (1991) descrivono altri quattro approcci
possibili, oltre a quello discusso qui, per costruire gli intervalli di
confidenza per il punteggio vero. L'approccio che abbiamo descritto è
accettato da tutti gli autori; le procedure alternative descritte da
@charter2001confidence, non sono invece accettate come valide da tutti
gli autori.

La più comune delle procedure alternative descritte da @charter2001confidence, che rappresenta l'approccio tradizionale a questo problema,
centra l'intervallo di confidenza sul punteggio osservato di un
rispondente e utilizza l'errore standard della misurazione per
calcolare i limiti dell'intervallo di confidenza:

$$
X_j \pm z_{\frac{\alpha}{2}} \sigma_E,
$$ 

dove $\sigma_E = \sigma_X \sqrt{1 -\rho_{XX^\prime}}$. Come abbiamo visto in precedenza, però, tale procedura non è corretta e non dovrebbe essere usata [es., @dudek1979continuing].

## Conclusioni

La teoria classica del punteggio vero prevede un modello additivo. Un punteggio osservato $X$ è la somma di due componenti: un punteggio vero stabile $T$ e un punteggio di errore casuale $E$. Si suppone che i punteggi di errore in un test non siano correlati con i punteggi veri in quel test e con i punteggi veri e di errore in tutti gli altri test. I test paralleli hanno gli stessi punteggi veri e le stesse varianze di errore. Si definiscono *sostanzialmente equivalenti* ($\tau$-equivalenti) i test che presentano punteggi veri che differiscono solamente per una costante additiva. Le assunzioni per la teoria classica del punteggio vero possono essere violate da diverse condizioni che influenzano i punteggi del test. Tuttavia, poiché non possiamo determinare direttamente $T$ ed $E$, non possiamo verificare direttamente l'appropriatezza delle assunzioni e possiamo solo supporre quando sarebbero appropriate.

I punteggi veri e i punteggi di errore sono costrutti teorici non osservabili. Possiamo osservare solo i punteggi $X$. Quando parliamo di punteggi veri, è necessario ricordare che un punteggio vero, ovvero un punteggio medio preso su ripetuti test indipendenti con lo stesso test, è un'idea teorica. Questo punteggio non rifletterà completamente la caratteristica "vera" di interesse a meno che il test non abbia una attendibilità perfetta, ovvero a meno che il test misuri esattamente ciò che afferma di misurare. 

### Vantaggi della CTT

Ci sono numerosi vantaggi nel lavorare nel framework della teoria classica dei test (CTT) durante lo sviluppo di test. In primo luogo, i concetti della CTT sono ampiamente insegnati e compresi. In secondo luogo, i concetti della CTT sono relativamente facili da imparare, usare e spiegare. Le statistiche descrittive dei test (ad esempio, la media, la deviazione standard, l'intervallo, ecc.) e le statistiche relative alle analisi degli item (in particolare la facilità e la discriminazione degli item) possono essere calcolate  facilmente. In terzo luogo, il modello CTT soddisfa molte esigenze di misurazione, in particolare per lo sviluppo di misure di competenza e di collocazione che possono aiutare nelle decisioni di ammissione, nei confronti tra programmi e nelle decisioni di collocazione in vari contesti lavorativi. In quarto luogo, giusto o sbagliato, il modello CTT consente e permette l'interpretazione dei punteggi degli esaminati del 0% e del 100% e delle stime di facilità degli item di 0.0 e di 1.0 - risultati che si verificano nel mondo reale. Tali punteggi degli esaminati (detti anche stime di abilità personale) e stime di facilità degli item sono generalmente considerati non adatti nei modelli di teoria di risposta agli item (IRT).

### Svantaggi della CTT

Tuttavia, lavorare all'interno del quadro CTT presenta anche alcuni svantaggi. In primo luogo, i test CTT tendono ad essere lunghi e necessariamente composti da elementi omogenei. In secondo luogo, gli esaminandi che completano test sviluppati attraverso i metodi CTT potrebbero dover affrontare numerosi item che sono troppo facili o troppo difficili per loro come individui. In terzo luogo, i risultati sui test CTT si applicano solo al campione preso in considerazione o a campioni molto simili. In quarto luogo, i risultati CTT si applicano solo alla selezione corrente di item. In quinto luogo, a causa della sua dipendenza dalla distribuzione normale, i CTT sono utili solo per lo sviluppo di test normativi. In sesto luogo, a causa della natura correlativa della discriminazione degli elementi, dell'affidabilità e di alcune stime di validità, gli item e i test CTT finiscono spesso per essere sensibili alle differenze tra gli estremi della scala. In settimo luogo, sebbene in realtà gli errori di misurazione su un test varino lungo tutto il range dei possibili punteggi in un test CTT (vale a dire, l'errore standard di misurazione è minore vicino alla media e diventa sempre più grande man mano che i punteggi si allontanano dalla media in entrambe le direzioni), l'errore standard di misurazione stimato nei CTT è una media su tutto questo intervallo.

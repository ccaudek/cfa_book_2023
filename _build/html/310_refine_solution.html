

<!DOCTYPE html>


<html >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>15. La revisione del modello &#8212; cfa_book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=12da95d707ffb74b382d" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=12da95d707ffb74b382d" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=12da95d707ffb74b382d" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=12da95d707ffb74b382d" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=12da95d707ffb74b382d" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=12da95d707ffb74b382d" />

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '310_refine_solution';</script>
    <link rel="shortcut icon" href="_static/increasing.png"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="16. LGM e modelli misti" href="324_lgm_mixed.html" />
    <link rel="prev" title="14. Indici di bontà dell’adattamento" href="300_gof.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="None"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Benvenuti
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Modello lineare</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="010_regression.html">1. L’analisi di regressione</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Teoria classica dei test</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="035_ctt.html">2. Fondamenti teorici</a></li>
<li class="toctree-l1"><a class="reference internal" href="037_err_std_mis.html">3. L’errore standard della misurazione</a></li>
<li class="toctree-l1"><a class="reference internal" href="038_err_std_stima.html">4. La stima del punteggio vero</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Analisi fattoriale</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="062_constraints_on_parms.html">5. Attendibilità e modello fattoriale</a></li>
<li class="toctree-l1"><a class="reference internal" href="070_cfa_mod_comp.html">6. CFA: confronto tra modelli</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Costruzione di strumenti psicometrici</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="200_problema_strumento.html">7. Tipologie dei test psicometrici</a></li>
<li class="toctree-l1"><a class="reference internal" href="201_valutare_le_matrici.html">8. Valutazione della matrice di correlazione</a></li>
<li class="toctree-l1"><a class="reference internal" href="202_estrazione.html">9. L’estrazione dei fattori</a></li>
<li class="toctree-l1"><a class="reference internal" href="203_numero_fattori.html">10. Il numero dei fattori</a></li>
<li class="toctree-l1"><a class="reference internal" href="205_rotazione.html">11. La rotazione fattoriale</a></li>
<li class="toctree-l1"><a class="reference internal" href="206_valutare_sol_fattoriale.html">12. Valutare e rifinire la soluzione fattoriale</a></li>
<li class="toctree-l1"><a class="reference internal" href="250_group_invariance.html">13. Invarianza di misura</a></li>
<li class="toctree-l1"><a class="reference internal" href="300_gof.html">14. Indici di bontà dell’adattamento</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">15. La revisione del modello</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Curve di crescita latente</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="324_lgm_mixed.html">16. LGM e modelli misti</a></li>
<li class="toctree-l1"><a class="reference internal" href="326_growth_1.html">17. Curve di crescita latente</a></li>
<li class="toctree-l1"><a class="reference internal" href="332_latent_change.html">18. Latent Change Score Modeling</a></li>
<li class="toctree-l1"><a class="reference internal" href="333_biv_change.html">19. LCSM bivariato</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Bibliografia</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="z_biblio.html">20. Bibliografia</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/ccaudek/cfa_book_2023" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/ccaudek/cfa_book_2023/issues/new?title=Issue%20on%20page%20%2F310_refine_solution.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/310_refine_solution.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>La revisione del modello</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#un-numero-di-fattori-troppo-piccolo">15.1. Un numero di fattori troppo piccolo</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#specificazione-errata-delle-relazioni-tra-indicatori-e-fattori-latenti">15.2. Specificazione errata delle relazioni tra indicatori e fattori latenti</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#saturazione-sul-fattore-sbagliato">15.3. Saturazione sul fattore sbagliato</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#commenti-e-considerazioni-finali">15.4. Commenti e considerazioni finali {-}</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="la-revisione-del-modello">
<span id="model-revision-notebook"></span><h1><span class="section-number">15. </span>La revisione del modello<a class="headerlink" href="#la-revisione-del-modello" title="Permalink to this headline">#</a></h1>
<p><span id="id1">Brown [<a class="reference internal" href="z_biblio.html#id32" title="Timothy A Brown. Confirmatory factor analysis for applied research. Guilford publications, 2015.">Bro15</a>]</span> discute alcune possibili cause che possono essere responsabili della mancanza di adattamento del modello EFA o CFA ai dati. In particolare, vengono esaminate le seguenti possibili cause:</p>
<ul class="simple">
<li><p>il ricercatore ha ipotizzato il numero sbagliato di fattori comuni latenti,</p></li>
<li><p>un item viene ipotizzato saturare su un solo fattore comune mentre satura su diversi fattori,</p></li>
<li><p>un item viene ipotizzato saturare sul fattore comune sbagliato,</p></li>
<li><p>è possibile che vi siano correlazioni residue che il modello non ha considerato.</p></li>
</ul>
<p><span id="id2">Brown [<a class="reference internal" href="z_biblio.html#id32" title="Timothy A Brown. Confirmatory factor analysis for applied research. Guilford publications, 2015.">Bro15</a>]</span> mostra come il ricercatore possa usare i <em>Modification Indices</em> per valutare le cause del mancato adattamento del modello ai dati.</p>
<section id="un-numero-di-fattori-troppo-piccolo">
<h2><span class="section-number">15.1. </span>Un numero di fattori troppo piccolo<a class="headerlink" href="#un-numero-di-fattori-troppo-piccolo" title="Permalink to this headline">#</a></h2>
<p>Una delle possibili fonti di mancanza di adattamento del modello può dipendere dal fatto che è stato ipotizzato un numero insufficiente di fattori latenti comuni. <span id="id3">Brown [<a class="reference internal" href="z_biblio.html#id32" title="Timothy A Brown. Confirmatory factor analysis for applied research. Guilford publications, 2015.">Bro15</a>]</span> discute il caso nel quale si confrontano gli indici di bontà di adattamento di un modello ad un solo fattore comune e un modello a due fattori comuni. L’esempio riguarda i dati già in precedenza discussi e relativi relativi a otto misure di personalità raccolte su un campione di 250 pazienti che hanno concluso un programma di psicoterapia. Le scale sono le seguenti:</p>
<ul class="simple">
<li><p>anxiety (N1),</p></li>
<li><p>hostility (N2),</p></li>
<li><p>depression (N3),</p></li>
<li><p>self-consciousness (N4),</p></li>
<li><p>warmth (E1),</p></li>
<li><p>gregariousness (E2),</p></li>
<li><p>assertiveness (E3),</p></li>
<li><p>positive emotions (E4).</p></li>
</ul>
<p>Leggiamo i dati in <span class="math notranslate nohighlight">\(\mathsf{R}\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">varnames</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s">&quot;N1&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;N2&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;N3&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;N4&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;E1&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;E2&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;E3&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;E4&quot;</span><span class="p">)</span>

<span class="n">sds</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">5.7</span><span class="p">,</span><span class="w">  </span><span class="m">5.6</span><span class="p">,</span><span class="w">  </span><span class="m">6.4</span><span class="p">,</span><span class="w">  </span><span class="m">5.7</span><span class="p">,</span><span class="w">  </span><span class="m">6.0</span><span class="p">,</span><span class="w">  </span><span class="m">6.2</span><span class="p">,</span><span class="w">  </span><span class="m">5.7</span><span class="p">,</span><span class="w">  </span><span class="m">5.6</span><span class="p">)</span>

<span class="n">cors</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="s">&#39;</span>
<span class="s"> 1.000</span>
<span class="s"> 0.767  1.000 </span>
<span class="s"> 0.731  0.709  1.000 </span>
<span class="s"> 0.778  0.738  0.762  1.000 </span>
<span class="s">-0.351  -0.302  -0.356  -0.318  1.000 </span>
<span class="s">-0.316  -0.280  -0.300  -0.267  0.675  1.000 </span>
<span class="s">-0.296  -0.289  -0.297  -0.296  0.634  0.651  1.000 </span>
<span class="s">-0.282  -0.254  -0.292  -0.245  0.534  0.593  0.566  1.000&#39;</span>

<span class="n">psychot_cor_mat</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">getCov</span><span class="p">(</span><span class="n">cors</span><span class="p">,</span><span class="w"> </span><span class="n">names</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">varnames</span><span class="p">)</span>

<span class="n">n</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">250</span>
</pre></div>
</div>
</div>
</div>
<p>Supponiamo di adattare ai dati il modello “sbagliato” che include un unico fattore comune.  Svolgiamo qui l’analisi <em>fattoriale esplorativa</em> usando la funzione sperimentale <code class="docutils literal notranslate"><span class="pre">efa()</span></code> di <code class="docutils literal notranslate"><span class="pre">lavaan</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># 1-factor model</span>
<span class="n">f1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="s">&#39;</span>
<span class="s">  efa(&quot;efa&quot;)*f1 =~ N1 + N2 + N3 + N4 + E1 + E2 + E3 + E4</span>
<span class="s">&#39;</span>
</pre></div>
</div>
</div>
</div>
<p>Adattiamo il modello ai dati.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">efa_f1</span><span class="w"> </span><span class="o">&lt;-</span>
<span class="w">  </span><span class="nf">cfa</span><span class="p">(</span>
<span class="w">    </span><span class="n">model</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">f1</span><span class="p">,</span>
<span class="w">    </span><span class="n">sample.cov</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">psychot_cor_mat</span><span class="p">,</span>
<span class="w">    </span><span class="n">sample.nobs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">250</span><span class="p">,</span>
<span class="w">    </span><span class="n">rotation</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;oblimin&quot;</span>
<span class="w">  </span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Consideriamo ora un modello a due fattori.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">f2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="s">&#39;</span>
<span class="s">  efa(&quot;efa&quot;)*f1 +</span>
<span class="s">  efa(&quot;efa&quot;)*f2 =~ N1 + N2 + N3 + N4 + E1 + E2 + E3 + E4</span>
<span class="s">&#39;</span>
</pre></div>
</div>
</div>
</div>
<p>Adattiamo il modello ai dati.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">efa_f2</span><span class="w"> </span><span class="o">&lt;-</span>
<span class="w">  </span><span class="nf">cfa</span><span class="p">(</span>
<span class="w">    </span><span class="n">model</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">f2</span><span class="p">,</span>
<span class="w">    </span><span class="n">sample.cov</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">psychot_cor_mat</span><span class="p">,</span>
<span class="w">    </span><span class="n">sample.nobs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">250</span><span class="p">,</span>
<span class="w">    </span><span class="n">rotation</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;oblimin&quot;</span>
<span class="w">  </span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Esaminiamo gli indici di bontà di adattamento.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># define the fit measures</span>
<span class="n">fit_measures_robust</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s">&quot;chisq&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;df&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;pvalue&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;cfi&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;tli&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;rmsea&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;srmr&quot;</span><span class="p">)</span>

<span class="c1"># collect them for each model</span>
<span class="nf">rbind</span><span class="p">(</span>
<span class="w">  </span><span class="nf">fitmeasures</span><span class="p">(</span><span class="n">efa_f1</span><span class="p">,</span><span class="w"> </span><span class="n">fit_measures_robust</span><span class="p">),</span>
<span class="w">  </span><span class="nf">fitmeasures</span><span class="p">(</span><span class="n">efa_f2</span><span class="p">,</span><span class="w"> </span><span class="n">fit_measures_robust</span><span class="p">)</span>
<span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">  </span><span class="c1"># wrangle</span>
<span class="w">  </span><span class="nf">data.frame</span><span class="p">()</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">  </span><span class="nf">mutate</span><span class="p">(</span>
<span class="w">    </span><span class="n">chisq</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">round</span><span class="p">(</span><span class="n">chisq</span><span class="p">,</span><span class="w"> </span><span class="n">digits</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">),</span>
<span class="w">    </span><span class="n">df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">as.integer</span><span class="p">(</span><span class="n">df</span><span class="p">),</span>
<span class="w">    </span><span class="n">pvalue</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">ifelse</span><span class="p">(</span><span class="n">pvalue</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;&lt; .001&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">pvalue</span><span class="p">)</span>
<span class="w">  </span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">  </span><span class="nf">mutate_at</span><span class="p">(</span><span class="nf">vars</span><span class="p">(</span><span class="n">cfi</span><span class="o">:</span><span class="n">srmr</span><span class="p">),</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="nf">round</span><span class="p">(</span><span class="n">.</span><span class="p">,</span><span class="w"> </span><span class="n">digits</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="dataframe">
<caption>A data.frame: 2 × 7</caption>
<thead>
	<tr><th scope=col>chisq</th><th scope=col>df</th><th scope=col>pvalue</th><th scope=col>cfi</th><th scope=col>tli</th><th scope=col>rmsea</th><th scope=col>srmr</th></tr>
	<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><td>375</td><td>20</td><td><span style=white-space:pre-wrap>&lt; .001           </span></td><td>0.71</td><td>0.594</td><td>0.267</td><td>0.187</td></tr>
	<tr><td> 10</td><td>13</td><td>0.709310449320062</td><td>1.00</td><td>1.006</td><td>0.000</td><td>0.010</td></tr>
</tbody>
</table>
</div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">effectsize</span><span class="o">::</span><span class="nf">interpret</span><span class="p">(</span><span class="n">efa_f1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="dataframe">
<caption>A data.frame: 10 × 4</caption>
<thead>
	<tr><th scope=col>Name</th><th scope=col>Value</th><th scope=col>Threshold</th><th scope=col>Interpretation</th></tr>
	<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;effctsz_&gt;</th></tr>
</thead>
<tbody>
	<tr><td>GFI  </td><td>0.6713421</td><td>0.95</td><td>poor        </td></tr>
	<tr><td>AGFI </td><td>0.4084158</td><td>0.90</td><td>poor        </td></tr>
	<tr><td>NFI  </td><td>0.7006460</td><td>0.90</td><td>poor        </td></tr>
	<tr><td>NNFI </td><td>0.5941736</td><td>0.90</td><td>poor        </td></tr>
	<tr><td>CFI  </td><td>0.7101240</td><td>0.90</td><td>poor        </td></tr>
	<tr><td>RMSEA</td><td>0.2665811</td><td>0.05</td><td>poor        </td></tr>
	<tr><td>SRMR </td><td>0.1873289</td><td>0.08</td><td>poor        </td></tr>
	<tr><td>RFI  </td><td>0.5809044</td><td>0.90</td><td>poor        </td></tr>
	<tr><td>PNFI </td><td>0.5004614</td><td>0.50</td><td>satisfactory</td></tr>
	<tr><td>IFI  </td><td>0.7120036</td><td>0.90</td><td>poor        </td></tr>
</tbody>
</table>
</div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">effectsize</span><span class="o">::</span><span class="nf">interpret</span><span class="p">(</span><span class="n">efa_f2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="dataframe">
<caption>A data.frame: 10 × 4</caption>
<thead>
	<tr><th scope=col>Name</th><th scope=col>Value</th><th scope=col>Threshold</th><th scope=col>Interpretation</th></tr>
	<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;effctsz_&gt;</th></tr>
</thead>
<tbody>
	<tr><td>GFI  </td><td>0.990554109</td><td>0.95</td><td>satisfactory</td></tr>
	<tr><td>AGFI </td><td>0.973842148</td><td>0.90</td><td>satisfactory</td></tr>
	<tr><td>NFI  </td><td>0.992174918</td><td>0.90</td><td>satisfactory</td></tr>
	<tr><td>NNFI </td><td>1.005603388</td><td>0.90</td><td>satisfactory</td></tr>
	<tr><td>CFI  </td><td>1.000000000</td><td>0.90</td><td>satisfactory</td></tr>
	<tr><td>RMSEA</td><td>0.000000000</td><td>0.05</td><td>satisfactory</td></tr>
	<tr><td>SRMR </td><td>0.009907613</td><td>0.08</td><td>satisfactory</td></tr>
	<tr><td>RFI  </td><td>0.983145977</td><td>0.90</td><td>satisfactory</td></tr>
	<tr><td>PNFI </td><td>0.460652640</td><td>0.50</td><td>poor        </td></tr>
	<tr><td>IFI  </td><td>1.002570123</td><td>0.90</td><td>satisfactory</td></tr>
</tbody>
</table>
</div></div>
</div>
<p>I risultati mostrano come, in un modello EFA, una soluzione a due fattori produca un adattamento adeguato, mentre ciò non si verifica con un modello ad un solo fattore.</p>
</section>
<section id="specificazione-errata-delle-relazioni-tra-indicatori-e-fattori-latenti">
<h2><span class="section-number">15.2. </span>Specificazione errata delle relazioni tra indicatori e fattori latenti<a class="headerlink" href="#specificazione-errata-delle-relazioni-tra-indicatori-e-fattori-latenti" title="Permalink to this headline">#</a></h2>
<p>Un’altra potenziale fonte di errata specificazione del modello CFA è una designazione errata delle relazioni tra indicatori e fattori latenti.</p>
<p>In questo esempio, un ricercatore ha sviluppato un questionario di 12 item (gli item sono valutati su scale da 0 a 8) progettato per valutare le motivazioni dei giovani adulti a consumare bevande alcoliche (Cooper, 1994). La misura aveva lo scopo di valutare tre aspetti di questo costrutto (4 item ciascuno): (1) motivazioni di coping (item 1–4), (2) motivazioni sociali (item 5–8) e (3) motivazioni di miglioramento (item 9 –12). I dati sono i seguenti.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">sds</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">2.06</span><span class="p">,</span><span class="w"> </span><span class="m">1.52</span><span class="p">,</span><span class="w"> </span><span class="m">1.92</span><span class="p">,</span><span class="w"> </span><span class="m">1.41</span><span class="p">,</span><span class="w"> </span><span class="m">1.73</span><span class="p">,</span><span class="w"> </span><span class="m">1.77</span><span class="p">,</span><span class="w"> </span><span class="m">2.49</span><span class="p">,</span><span class="w"> </span><span class="m">2.27</span><span class="p">,</span><span class="w"> </span><span class="m">2.68</span><span class="p">,</span><span class="w"> </span><span class="m">1.75</span><span class="p">,</span><span class="w"> </span><span class="m">2.57</span><span class="p">,</span><span class="w"> </span><span class="m">2.66</span><span class="p">)</span>

<span class="n">cors</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="s">&#39;</span>
<span class="s">  1.000 </span>
<span class="s">  0.300  1.000 </span>
<span class="s">  0.229  0.261  1.000 </span>
<span class="s">  0.411  0.406  0.429  1.000 </span>
<span class="s">  0.172  0.252  0.218  0.481  1.000 </span>
<span class="s">  0.214  0.268  0.267  0.579  0.484  1.000 </span>
<span class="s">  0.200  0.214  0.241  0.543  0.426  0.492  1.000 </span>
<span class="s">  0.185  0.230  0.185  0.545  0.463  0.548  0.522  1.000 </span>
<span class="s">  0.134  0.146  0.108  0.186  0.122  0.131  0.108  0.151  1.000 </span>
<span class="s">  0.134  0.099  0.061  0.223  0.133  0.188  0.105  0.170  0.448  1.000 </span>
<span class="s">  0.160  0.131  0.158  0.161  0.044  0.124  0.066  0.061  0.370  0.350  1.000 </span>
<span class="s">  0.087  0.088  0.101  0.198  0.077  0.177  0.128  0.112  0.356  0.359  0.507  1.000&#39;</span>

<span class="n">covs</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">getCov</span><span class="p">(</span><span class="n">cors</span><span class="p">,</span><span class="w"> </span><span class="n">sds</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sds</span><span class="p">,</span><span class="w"> </span><span class="n">names</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">paste</span><span class="p">(</span><span class="s">&quot;x&quot;</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="m">12</span><span class="p">,</span><span class="w"> </span><span class="n">sep</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>Iniziamo con un modello che ipotizza tre fattori comuni latenti correlati, coerentemente con la motivazione che stava alla base della costruzione dello strumento.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">model1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="s">&#39;</span>
<span class="s">  copingm  =~ x1 + x2 + x3 + x4</span>
<span class="s">  socialm  =~ x5 + x6 + x7 + x8</span>
<span class="s">  enhancem =~ x9 + x10 + x11 + x12</span>
<span class="s">&#39;</span>
</pre></div>
</div>
</div>
</div>
<p>Adattiamo il modello ai dati.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">fit1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">cfa</span><span class="p">(</span>
<span class="w">  </span><span class="n">model1</span><span class="p">,</span><span class="w"> </span>
<span class="w">  </span><span class="n">sample.cov</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">covs</span><span class="p">,</span><span class="w"> </span>
<span class="w">  </span><span class="n">sample.nobs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">500</span><span class="p">,</span><span class="w"> </span>
<span class="w">  </span><span class="n">mimic</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;mplus&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Warning message in lavaan::lavaan(model = model1, sample.cov = covs, sample.nobs = 500, :
“lavaan WARNING:
    sample.mean= argument is missing, but model contains
    mean/intercept parameters.”
</pre></div>
</div>
</div>
</div>
<p>Esaminando le misure di adattamento potremmo concludere che il modello è adeguato.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">effectsize</span><span class="o">::</span><span class="nf">interpret</span><span class="p">(</span><span class="n">fit1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="dataframe">
<caption>A data.frame: 10 × 4</caption>
<thead>
	<tr><th scope=col>Name</th><th scope=col>Value</th><th scope=col>Threshold</th><th scope=col>Interpretation</th></tr>
	<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;effctsz_&gt;</th></tr>
</thead>
<tbody>
	<tr><td>GFI  </td><td>0.97009178</td><td>0.95</td><td>satisfactory</td></tr>
	<tr><td>AGFI </td><td>0.94722078</td><td>0.90</td><td>satisfactory</td></tr>
	<tr><td>NFI  </td><td>0.94785001</td><td>0.90</td><td>satisfactory</td></tr>
	<tr><td>NNFI </td><td>0.97102541</td><td>0.90</td><td>satisfactory</td></tr>
	<tr><td>CFI  </td><td>0.97761054</td><td>0.90</td><td>satisfactory</td></tr>
	<tr><td>RMSEA</td><td>0.03745791</td><td>0.05</td><td>satisfactory</td></tr>
	<tr><td>SRMR </td><td>0.03438699</td><td>0.08</td><td>satisfactory</td></tr>
	<tr><td>RFI  </td><td>0.93251177</td><td>0.90</td><td>satisfactory</td></tr>
	<tr><td>PNFI </td><td>0.73242955</td><td>0.50</td><td>satisfactory</td></tr>
	<tr><td>IFI  </td><td>0.97781875</td><td>0.90</td><td>satisfactory</td></tr>
</tbody>
</table>
</div></div>
</div>
<p>Tuttavia, un esame più attento mette in evidenza un comportamento anomalo dell’item <code class="docutils literal notranslate"><span class="pre">x4</span></code> e alcune caratteristiche anomale del modello in generale.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">standardizedSolution</span><span class="p">(</span><span class="n">fit1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="dataframe">
<caption>A lavaan.data.frame: 45 × 9</caption>
<thead>
	<tr><th scope=col>lhs</th><th scope=col>op</th><th scope=col>rhs</th><th scope=col>est.std</th><th scope=col>se</th><th scope=col>z</th><th scope=col>pvalue</th><th scope=col>ci.lower</th><th scope=col>ci.upper</th></tr>
	<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><td>copingm </td><td>=~</td><td>x1      </td><td>0.43164226</td><td>0.03913432</td><td>11.029763</td><td>0.000000e+00</td><td> 3.549404e-01</td><td>0.50834412</td></tr>
	<tr><td>copingm </td><td>=~</td><td>x2      </td><td>0.43575459</td><td>0.03899692</td><td>11.174078</td><td>0.000000e+00</td><td> 3.593220e-01</td><td>0.51218714</td></tr>
	<tr><td>copingm </td><td>=~</td><td>x3      </td><td>0.45123780</td><td>0.03847027</td><td>11.729519</td><td>0.000000e+00</td><td> 3.758375e-01</td><td>0.52663815</td></tr>
	<tr><td>copingm </td><td>=~</td><td>x4      </td><td>0.95323010</td><td>0.02446252</td><td>38.966968</td><td>0.000000e+00</td><td> 9.052845e-01</td><td>1.00117576</td></tr>
	<tr><td>socialm </td><td>=~</td><td>x5      </td><td>0.63324280</td><td>0.03156182</td><td>20.063571</td><td>0.000000e+00</td><td> 5.713828e-01</td><td>0.69510283</td></tr>
	<tr><td>socialm </td><td>=~</td><td>x6      </td><td>0.74779892</td><td>0.02546753</td><td>29.362831</td><td>0.000000e+00</td><td> 6.978835e-01</td><td>0.79771437</td></tr>
	<tr><td>socialm </td><td>=~</td><td>x7      </td><td>0.68994737</td><td>0.02856498</td><td>24.153608</td><td>0.000000e+00</td><td> 6.339610e-01</td><td>0.74593371</td></tr>
	<tr><td>socialm </td><td>=~</td><td>x8      </td><td>0.72872974</td><td>0.02648066</td><td>27.519319</td><td>0.000000e+00</td><td> 6.768286e-01</td><td>0.78063089</td></tr>
	<tr><td>enhancem</td><td>=~</td><td>x9      </td><td>0.60199381</td><td>0.03863571</td><td>15.581280</td><td>0.000000e+00</td><td> 5.262692e-01</td><td>0.67771841</td></tr>
	<tr><td>enhancem</td><td>=~</td><td>x10     </td><td>0.59737620</td><td>0.03879788</td><td>15.397135</td><td>0.000000e+00</td><td> 5.213338e-01</td><td>0.67341864</td></tr>
	<tr><td>enhancem</td><td>=~</td><td>x11     </td><td>0.66071892</td><td>0.03674260</td><td>17.982369</td><td>0.000000e+00</td><td> 5.887048e-01</td><td>0.73273309</td></tr>
	<tr><td>enhancem</td><td>=~</td><td>x12     </td><td>0.66516965</td><td>0.03661334</td><td>18.167412</td><td>0.000000e+00</td><td> 5.934088e-01</td><td>0.73693048</td></tr>
	<tr><td>x1      </td><td>~~</td><td>x1      </td><td>0.81368496</td><td>0.03378405</td><td>24.084882</td><td>0.000000e+00</td><td> 7.474694e-01</td><td>0.87990049</td></tr>
	<tr><td>x2      </td><td>~~</td><td>x2      </td><td>0.81011794</td><td>0.03398617</td><td>23.836695</td><td>0.000000e+00</td><td> 7.435063e-01</td><td>0.87672961</td></tr>
	<tr><td>x3      </td><td>~~</td><td>x3      </td><td>0.79638445</td><td>0.03471848</td><td>22.938343</td><td>0.000000e+00</td><td> 7.283375e-01</td><td>0.86443142</td></tr>
	<tr><td>x4      </td><td>~~</td><td>x4      </td><td>0.09135237</td><td>0.04663681</td><td> 1.958804</td><td>5.013577e-02</td><td>-5.410864e-05</td><td>0.18275884</td></tr>
	<tr><td>x5      </td><td>~~</td><td>x5      </td><td>0.59900356</td><td>0.03997259</td><td>14.985358</td><td>0.000000e+00</td><td> 5.206587e-01</td><td>0.67734839</td></tr>
	<tr><td>x6      </td><td>~~</td><td>x6      </td><td>0.44079677</td><td>0.03808919</td><td>11.572753</td><td>0.000000e+00</td><td> 3.661433e-01</td><td>0.51545021</td></tr>
	<tr><td>x7      </td><td>~~</td><td>x7      </td><td>0.52397262</td><td>0.03941667</td><td>13.293174</td><td>0.000000e+00</td><td> 4.467174e-01</td><td>0.60122788</td></tr>
	<tr><td>x8      </td><td>~~</td><td>x8      </td><td>0.46895296</td><td>0.03859449</td><td>12.150775</td><td>0.000000e+00</td><td> 3.933091e-01</td><td>0.54459677</td></tr>
	<tr><td>x9      </td><td>~~</td><td>x9      </td><td>0.63760346</td><td>0.04651692</td><td>13.706916</td><td>0.000000e+00</td><td> 5.464320e-01</td><td>0.72877494</td></tr>
	<tr><td>x10     </td><td>~~</td><td>x10     </td><td>0.64314168</td><td>0.04635386</td><td>13.874609</td><td>0.000000e+00</td><td> 5.522898e-01</td><td>0.73399357</td></tr>
	<tr><td>x11     </td><td>~~</td><td>x11     </td><td>0.56345051</td><td>0.04855306</td><td>11.604841</td><td>0.000000e+00</td><td> 4.682883e-01</td><td>0.65861275</td></tr>
	<tr><td>x12     </td><td>~~</td><td>x12     </td><td>0.55754934</td><td>0.04870817</td><td>11.446732</td><td>0.000000e+00</td><td> 4.620831e-01</td><td>0.65301559</td></tr>
	<tr><td>copingm </td><td>~~</td><td>copingm </td><td>1.00000000</td><td>0.00000000</td><td>       NA</td><td>          NA</td><td> 1.000000e+00</td><td>1.00000000</td></tr>
	<tr><td>socialm </td><td>~~</td><td>socialm </td><td>1.00000000</td><td>0.00000000</td><td>       NA</td><td>          NA</td><td> 1.000000e+00</td><td>1.00000000</td></tr>
	<tr><td>enhancem</td><td>~~</td><td>enhancem</td><td>1.00000000</td><td>0.00000000</td><td>       NA</td><td>          NA</td><td> 1.000000e+00</td><td>1.00000000</td></tr>
	<tr><td>copingm </td><td>~~</td><td>socialm </td><td>0.79871805</td><td>0.03054429</td><td>26.149508</td><td>0.000000e+00</td><td> 7.388524e-01</td><td>0.85858375</td></tr>
	<tr><td>copingm </td><td>~~</td><td>enhancem</td><td>0.32194358</td><td>0.05081203</td><td> 6.335971</td><td>2.358509e-10</td><td> 2.223538e-01</td><td>0.42153334</td></tr>
	<tr><td>socialm </td><td>~~</td><td>enhancem</td><td>0.26764339</td><td>0.05555677</td><td> 4.817476</td><td>1.453857e-06</td><td> 1.587541e-01</td><td>0.37653266</td></tr>
	<tr><td>x1      </td><td>~1</td><td>        </td><td>0.00000000</td><td>0.04472136</td><td> 0.000000</td><td>1.000000e+00</td><td>-8.765225e-02</td><td>0.08765225</td></tr>
	<tr><td>x2      </td><td>~1</td><td>        </td><td>0.00000000</td><td>0.04472136</td><td> 0.000000</td><td>1.000000e+00</td><td>-8.765225e-02</td><td>0.08765225</td></tr>
	<tr><td>x3      </td><td>~1</td><td>        </td><td>0.00000000</td><td>0.04472136</td><td> 0.000000</td><td>1.000000e+00</td><td>-8.765225e-02</td><td>0.08765225</td></tr>
	<tr><td>x4      </td><td>~1</td><td>        </td><td>0.00000000</td><td>0.04472136</td><td> 0.000000</td><td>1.000000e+00</td><td>-8.765225e-02</td><td>0.08765225</td></tr>
	<tr><td>x5      </td><td>~1</td><td>        </td><td>0.00000000</td><td>0.04472136</td><td> 0.000000</td><td>1.000000e+00</td><td>-8.765225e-02</td><td>0.08765225</td></tr>
	<tr><td>x6      </td><td>~1</td><td>        </td><td>0.00000000</td><td>0.04472136</td><td> 0.000000</td><td>1.000000e+00</td><td>-8.765225e-02</td><td>0.08765225</td></tr>
	<tr><td>x7      </td><td>~1</td><td>        </td><td>0.00000000</td><td>0.04472136</td><td> 0.000000</td><td>1.000000e+00</td><td>-8.765225e-02</td><td>0.08765225</td></tr>
	<tr><td>x8      </td><td>~1</td><td>        </td><td>0.00000000</td><td>0.04472136</td><td> 0.000000</td><td>1.000000e+00</td><td>-8.765225e-02</td><td>0.08765225</td></tr>
	<tr><td>x9      </td><td>~1</td><td>        </td><td>0.00000000</td><td>0.04472136</td><td> 0.000000</td><td>1.000000e+00</td><td>-8.765225e-02</td><td>0.08765225</td></tr>
	<tr><td>x10     </td><td>~1</td><td>        </td><td>0.00000000</td><td>0.04472136</td><td> 0.000000</td><td>1.000000e+00</td><td>-8.765225e-02</td><td>0.08765225</td></tr>
	<tr><td>x11     </td><td>~1</td><td>        </td><td>0.00000000</td><td>0.04472136</td><td> 0.000000</td><td>1.000000e+00</td><td>-8.765225e-02</td><td>0.08765225</td></tr>
	<tr><td>x12     </td><td>~1</td><td>        </td><td>0.00000000</td><td>0.04472136</td><td> 0.000000</td><td>1.000000e+00</td><td>-8.765225e-02</td><td>0.08765225</td></tr>
	<tr><td>copingm </td><td>~1</td><td>        </td><td>0.00000000</td><td>0.00000000</td><td>       NA</td><td>          NA</td><td> 0.000000e+00</td><td>0.00000000</td></tr>
	<tr><td>socialm </td><td>~1</td><td>        </td><td>0.00000000</td><td>0.00000000</td><td>       NA</td><td>          NA</td><td> 0.000000e+00</td><td>0.00000000</td></tr>
	<tr><td>enhancem</td><td>~1</td><td>        </td><td>0.00000000</td><td>0.00000000</td><td>       NA</td><td>          NA</td><td> 0.000000e+00</td><td>0.00000000</td></tr>
</tbody>
</table>
</div></div>
</div>
<p>In particolare, l’item <code class="docutils literal notranslate"><span class="pre">x4</span></code> mostra una saturazione molto forte sul fattore Motivi di coping (.955) ed emerge una correlazione molto alta tra i fattori Motivi di coping e Motivi sociali (.798).</p>
<p>&#64;brown2015confirmatory suggerisce di esaminare i <em>Modification Indices</em>. Tale esame mostra che il MI associato a <code class="docutils literal notranslate"><span class="pre">x4</span></code> è molto alto, 18.916.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">modindices</span><span class="p">(</span><span class="n">fit1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="dataframe">
<caption>A lavaan.data.frame: 90 × 8</caption>
<thead>
	<tr><th></th><th scope=col>lhs</th><th scope=col>op</th><th scope=col>rhs</th><th scope=col>mi</th><th scope=col>epc</th><th scope=col>sepc.lv</th><th scope=col>sepc.all</th><th scope=col>sepc.nox</th></tr>
	<tr><th></th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><th scope=row>46</th><td>copingm </td><td>=~</td><td>x5 </td><td> 0.030005989</td><td>-0.029864968</td><td>-0.026528841</td><td>-0.015349946</td><td>-0.015349946</td></tr>
	<tr><th scope=row>47</th><td>copingm </td><td>=~</td><td>x6 </td><td> 0.483607013</td><td> 0.126715141</td><td> 0.112560167</td><td> 0.063657017</td><td> 0.063657017</td></tr>
	<tr><th scope=row>48</th><td>copingm </td><td>=~</td><td>x7 </td><td> 0.779713184</td><td> 0.220132468</td><td> 0.195542120</td><td> 0.078609654</td><td> 0.078609654</td></tr>
	<tr><th scope=row>49</th><td>copingm </td><td>=~</td><td>x8 </td><td> 1.962276016</td><td>-0.323442154</td><td>-0.287311386</td><td>-0.126695694</td><td>-0.126695694</td></tr>
	<tr><th scope=row>50</th><td>copingm </td><td>=~</td><td>x9 </td><td> 0.101119531</td><td> 0.044105439</td><td> 0.039178551</td><td> 0.014633498</td><td> 0.014633498</td></tr>
	<tr><th scope=row>51</th><td>copingm </td><td>=~</td><td>x10</td><td> 2.016179576</td><td> 0.128686040</td><td> 0.114310902</td><td> 0.065385941</td><td> 0.065385941</td></tr>
	<tr><th scope=row>52</th><td>copingm </td><td>=~</td><td>x11</td><td> 1.870017679</td><td>-0.181368830</td><td>-0.161108654</td><td>-0.062750981</td><td>-0.062750981</td></tr>
	<tr><th scope=row>53</th><td>copingm </td><td>=~</td><td>x12</td><td> 0.039774895</td><td>-0.027386556</td><td>-0.024327285</td><td>-0.009154759</td><td>-0.009154759</td></tr>
	<tr><th scope=row>54</th><td>socialm </td><td>=~</td><td>x1 </td><td> 6.926785939</td><td>-0.520304949</td><td>-0.569429069</td><td>-0.276698865</td><td>-0.276698865</td></tr>
	<tr><th scope=row>55</th><td>socialm </td><td>=~</td><td>x2 </td><td> 0.052053171</td><td>-0.033339419</td><td>-0.036487130</td><td>-0.024028734</td><td>-0.024028734</td></tr>
	<tr><th scope=row>56</th><td>socialm </td><td>=~</td><td>x3 </td><td> 2.058455483</td><td>-0.266795427</td><td>-0.291984676</td><td>-0.152227711</td><td>-0.152227711</td></tr>
	<tr><th scope=row>57</th><td>socialm </td><td>=~</td><td>x4 </td><td>18.916304911</td><td> 1.300066952</td><td> 1.422811595</td><td> 1.010097106</td><td> 1.010097106</td></tr>
	<tr><th scope=row>58</th><td>socialm </td><td>=~</td><td>x9 </td><td> 0.338261984</td><td> 0.066907544</td><td> 0.073224559</td><td> 0.027349952</td><td> 0.027349952</td></tr>
	<tr><th scope=row>59</th><td>socialm </td><td>=~</td><td>x10</td><td> 2.883617084</td><td> 0.127660732</td><td> 0.139713704</td><td> 0.079916367</td><td> 0.079916367</td></tr>
	<tr><th scope=row>60</th><td>socialm </td><td>=~</td><td>x11</td><td> 4.357439140</td><td>-0.229221561</td><td>-0.250863307</td><td>-0.097709951</td><td>-0.097709951</td></tr>
	<tr><th scope=row>61</th><td>socialm </td><td>=~</td><td>x12</td><td> 0.001070604</td><td> 0.003719464</td><td> 0.004070634</td><td> 0.001531847</td><td> 0.001531847</td></tr>
	<tr><th scope=row>62</th><td>enhancem</td><td>=~</td><td>x1 </td><td> 1.954056978</td><td> 0.092553029</td><td> 0.149170471</td><td> 0.072485411</td><td> 0.072485411</td></tr>
	<tr><th scope=row>63</th><td>enhancem</td><td>=~</td><td>x2 </td><td> 0.862633625</td><td> 0.045296430</td><td> 0.073005605</td><td> 0.048078110</td><td> 0.048078110</td></tr>
	<tr><th scope=row>64</th><td>enhancem</td><td>=~</td><td>x3 </td><td> 0.379815944</td><td> 0.037713503</td><td> 0.060783976</td><td> 0.031690038</td><td> 0.031690038</td></tr>
	<tr><th scope=row>65</th><td>enhancem</td><td>=~</td><td>x4 </td><td> 3.101582135</td><td>-0.103926028</td><td>-0.167500673</td><td>-0.118913808</td><td>-0.118913808</td></tr>
	<tr><th scope=row>66</th><td>enhancem</td><td>=~</td><td>x5 </td><td> 0.595829582</td><td>-0.038973519</td><td>-0.062814781</td><td>-0.036345482</td><td>-0.036345482</td></tr>
	<tr><th scope=row>67</th><td>enhancem</td><td>=~</td><td>x6 </td><td> 2.495315594</td><td> 0.077609406</td><td> 0.125085390</td><td> 0.070740502</td><td> 0.070740502</td></tr>
	<tr><th scope=row>68</th><td>enhancem</td><td>=~</td><td>x7 </td><td> 0.538673545</td><td>-0.051861381</td><td>-0.083586531</td><td>-0.033602521</td><td>-0.033602521</td></tr>
	<tr><th scope=row>69</th><td>enhancem</td><td>=~</td><td>x8 </td><td> 0.093095151</td><td>-0.019336415</td><td>-0.031165076</td><td>-0.013742863</td><td>-0.013742863</td></tr>
	<tr><th scope=row>70</th><td>x1      </td><td>~~</td><td>x2 </td><td>10.298966995</td><td> 0.379140628</td><td> 0.379140628</td><td> 0.149436604</td><td> 0.149436604</td></tr>
	<tr><th scope=row>71</th><td>x1      </td><td>~~</td><td>x3 </td><td> 0.985767890</td><td> 0.147339714</td><td> 0.147339714</td><td> 0.046369423</td><td> 0.046369423</td></tr>
	<tr><th scope=row>72</th><td>x1      </td><td>~~</td><td>x4 </td><td> 0.015598853</td><td>-0.014806108</td><td>-0.014806108</td><td>-0.018734251</td><td>-0.018734251</td></tr>
	<tr><th scope=row>73</th><td>x1      </td><td>~~</td><td>x5 </td><td> 0.451852422</td><td>-0.080302627</td><td>-0.080302627</td><td>-0.032340240</td><td>-0.032340240</td></tr>
	<tr><th scope=row>74</th><td>x1      </td><td>~~</td><td>x6 </td><td> 0.484485902</td><td>-0.077883982</td><td>-0.077883982</td><td>-0.035737988</td><td>-0.035737988</td></tr>
	<tr><th scope=row>75</th><td>x1      </td><td>~~</td><td>x7 </td><td> 0.289527960</td><td>-0.088717149</td><td>-0.088717149</td><td>-0.026541682</td><td>-0.026541682</td></tr>
	<tr><th scope=row>⋮</th><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td></tr>
	<tr><th scope=row>106</th><td>x4 </td><td>~~</td><td>x11</td><td> 2.637247586</td><td>-0.14863761</td><td>-0.14863761</td><td>-0.181158325</td><td>-0.181158325</td></tr>
	<tr><th scope=row>107</th><td>x4 </td><td>~~</td><td>x12</td><td> 0.169101191</td><td> 0.03892761</td><td> 0.03892761</td><td> 0.046081350</td><td> 0.046081350</td></tr>
	<tr><th scope=row>108</th><td>x5 </td><td>~~</td><td>x6 </td><td> 0.369571094</td><td> 0.05700901</td><td> 0.05700901</td><td> 0.036304439</td><td> 0.036304439</td></tr>
	<tr><th scope=row>109</th><td>x5 </td><td>~~</td><td>x7 </td><td> 0.292001629</td><td>-0.07226591</td><td>-0.07226591</td><td>-0.030004653</td><td>-0.030004653</td></tr>
	<tr><th scope=row>110</th><td>x5 </td><td>~~</td><td>x8 </td><td> 0.007087368</td><td> 0.01015175</td><td> 0.01015175</td><td> 0.004887190</td><td> 0.004887190</td></tr>
	<tr><th scope=row>111</th><td>x5 </td><td>~~</td><td>x9 </td><td> 0.822203615</td><td> 0.13325873</td><td> 0.13325873</td><td> 0.046600871</td><td> 0.046600871</td></tr>
	<tr><th scope=row>112</th><td>x5 </td><td>~~</td><td>x10</td><td> 0.339106523</td><td> 0.05600380</td><td> 0.05600380</td><td> 0.029863092</td><td> 0.029863092</td></tr>
	<tr><th scope=row>113</th><td>x5 </td><td>~~</td><td>x11</td><td> 1.125776934</td><td>-0.14545894</td><td>-0.14545894</td><td>-0.056427145</td><td>-0.056427145</td></tr>
	<tr><th scope=row>114</th><td>x5 </td><td>~~</td><td>x12</td><td> 1.143486321</td><td>-0.15142439</td><td>-0.15142439</td><td>-0.057053374</td><td>-0.057053374</td></tr>
	<tr><th scope=row>115</th><td>x6 </td><td>~~</td><td>x7 </td><td> 2.528078433</td><td>-0.21453919</td><td>-0.21453919</td><td>-0.101491633</td><td>-0.101491633</td></tr>
	<tr><th scope=row>116</th><td>x6 </td><td>~~</td><td>x8 </td><td> 0.052656710</td><td> 0.02855951</td><td> 0.02855951</td><td> 0.015665253</td><td> 0.015665253</td></tr>
	<tr><th scope=row>117</th><td>x6 </td><td>~~</td><td>x9 </td><td> 1.055994918</td><td>-0.14050502</td><td>-0.14050502</td><td>-0.055983319</td><td>-0.055983319</td></tr>
	<tr><th scope=row>118</th><td>x6 </td><td>~~</td><td>x10</td><td> 0.598393109</td><td> 0.06920893</td><td> 0.06920893</td><td> 0.042048247</td><td> 0.042048247</td></tr>
	<tr><th scope=row>119</th><td>x6 </td><td>~~</td><td>x11</td><td> 0.248120056</td><td> 0.06361858</td><td> 0.06361858</td><td> 0.028119014</td><td> 0.028119014</td></tr>
	<tr><th scope=row>120</th><td>x6 </td><td>~~</td><td>x12</td><td> 1.667231850</td><td> 0.17036266</td><td> 0.17036266</td><td> 0.073135524</td><td> 0.073135524</td></tr>
	<tr><th scope=row>121</th><td>x7 </td><td>~~</td><td>x8 </td><td> 1.430701442</td><td> 0.20641391</td><td> 0.20641391</td><td> 0.073818398</td><td> 0.073818398</td></tr>
	<tr><th scope=row>122</th><td>x7 </td><td>~~</td><td>x9 </td><td> 0.031974082</td><td>-0.03617847</td><td>-0.03617847</td><td>-0.009398444</td><td>-0.009398444</td></tr>
	<tr><th scope=row>123</th><td>x7 </td><td>~~</td><td>x10</td><td> 1.520595023</td><td>-0.16326316</td><td>-0.16326316</td><td>-0.064671491</td><td>-0.064671491</td></tr>
	<tr><th scope=row>124</th><td>x7 </td><td>~~</td><td>x11</td><td> 0.262702017</td><td>-0.09678497</td><td>-0.09678497</td><td>-0.027890928</td><td>-0.027890928</td></tr>
	<tr><th scope=row>125</th><td>x7 </td><td>~~</td><td>x12</td><td> 0.637279724</td><td> 0.15571434</td><td> 0.15571434</td><td> 0.043583441</td><td> 0.043583441</td></tr>
	<tr><th scope=row>126</th><td>x8 </td><td>~~</td><td>x9 </td><td> 1.621415958</td><td> 0.22713544</td><td> 0.22713544</td><td> 0.068415381</td><td> 0.068415381</td></tr>
	<tr><th scope=row>127</th><td>x8 </td><td>~~</td><td>x10</td><td> 1.311207860</td><td> 0.13365654</td><td> 0.13365654</td><td> 0.061387222</td><td> 0.061387222</td></tr>
	<tr><th scope=row>128</th><td>x8 </td><td>~~</td><td>x11</td><td> 2.143803609</td><td>-0.24388059</td><td>-0.24388059</td><td>-0.081488322</td><td>-0.081488322</td></tr>
	<tr><th scope=row>129</th><td>x8 </td><td>~~</td><td>x12</td><td> 0.590763954</td><td>-0.13225157</td><td>-0.13225157</td><td>-0.042919717</td><td>-0.042919717</td></tr>
	<tr><th scope=row>130</th><td>x9 </td><td>~~</td><td>x10</td><td>19.845889390</td><td> 0.86196909</td><td> 0.86196909</td><td> 0.287580582</td><td> 0.287580582</td></tr>
	<tr><th scope=row>131</th><td>x9 </td><td>~~</td><td>x11</td><td> 2.908067952</td><td>-0.51760251</td><td>-0.51760251</td><td>-0.125630360</td><td>-0.125630360</td></tr>
	<tr><th scope=row>132</th><td>x9 </td><td>~~</td><td>x12</td><td> 7.696109928</td><td>-0.87624430</td><td>-0.87624430</td><td>-0.206567170</td><td>-0.206567170</td></tr>
	<tr><th scope=row>133</th><td>x10</td><td>~~</td><td>x11</td><td> 7.331168352</td><td>-0.53355625</td><td>-0.53355625</td><td>-0.197468293</td><td>-0.197468293</td></tr>
	<tr><th scope=row>134</th><td>x10</td><td>~~</td><td>x12</td><td> 5.572004260</td><td>-0.48399514</td><td>-0.48399514</td><td>-0.173978677</td><td>-0.173978677</td></tr>
	<tr><th scope=row>135</th><td>x11</td><td>~~</td><td>x12</td><td>26.947310645</td><td> 1.71105153</td><td> 1.71105153</td><td> 0.447454092</td><td> 0.447454092</td></tr>
</tbody>
</table>
</div></div>
</div>
<p>Le considerazioni precedenti, dunque, suggeriscono che il modello potrebbe non avere descritto in maniera adeguata le relazioni tra <code class="docutils literal notranslate"><span class="pre">x4</span></code> e i fattori comuni latenti.  In base a considerazioni teoriche, supponiamo che abbia senso pensare che <code class="docutils literal notranslate"><span class="pre">x4</span></code> saturi non solo sul fattore Motivi di coping ma anche sul fattore di Motivi Sociali. Specifichiamo dunque un nuovo modello nel modo seguente.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">model2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="s">&#39;</span>
<span class="s">  copingm  =~ x1 + x2 + x3 + x4</span>
<span class="s">  socialm  =~ x4 + x5 + x6 + x7 + x8</span>
<span class="s">  enhancem =~ x9 + x10 + x11 + x12</span>
<span class="s">&#39;</span>
</pre></div>
</div>
</div>
</div>
<p>Adattiamo il modello.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">fit2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">cfa</span><span class="p">(</span>
<span class="w">  </span><span class="n">model2</span><span class="p">,</span><span class="w"> </span>
<span class="w">  </span><span class="n">sample.cov</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">covs</span><span class="p">,</span><span class="w"> </span>
<span class="w">  </span><span class="n">sample.nobs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">500</span><span class="p">,</span><span class="w"> </span>
<span class="w">  </span><span class="n">mimic</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;mplus&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Warning message in lavaan::lavaan(model = model2, sample.cov = covs, sample.nobs = 500, :
“lavaan WARNING:
    sample.mean= argument is missing, but model contains
    mean/intercept parameters.”
</pre></div>
</div>
</div>
</div>
<p>Esaminiamo gli indici di bontà di adattamento.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">effectsize</span><span class="o">::</span><span class="nf">interpret</span><span class="p">(</span><span class="n">fit2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="dataframe">
<caption>A data.frame: 10 × 4</caption>
<thead>
	<tr><th scope=col>Name</th><th scope=col>Value</th><th scope=col>Threshold</th><th scope=col>Interpretation</th></tr>
	<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;effctsz_&gt;</th></tr>
</thead>
<tbody>
	<tr><td>GFI  </td><td>0.97684139</td><td>0.95</td><td>satisfactory</td></tr>
	<tr><td>AGFI </td><td>0.95831451</td><td>0.90</td><td>satisfactory</td></tr>
	<tr><td>NFI  </td><td>0.95826773</td><td>0.90</td><td>satisfactory</td></tr>
	<tr><td>NNFI </td><td>0.98393923</td><td>0.90</td><td>satisfactory</td></tr>
	<tr><td>CFI  </td><td>0.98783275</td><td>0.90</td><td>satisfactory</td></tr>
	<tr><td>RMSEA</td><td>0.02788804</td><td>0.05</td><td>satisfactory</td></tr>
	<tr><td>SRMR </td><td>0.02887855</td><td>0.08</td><td>satisfactory</td></tr>
	<tr><td>RFI  </td><td>0.94491340</td><td>0.90</td><td>satisfactory</td></tr>
	<tr><td>PNFI </td><td>0.72596040</td><td>0.50</td><td>satisfactory</td></tr>
	<tr><td>IFI  </td><td>0.98795337</td><td>0.90</td><td>satisfactory</td></tr>
</tbody>
</table>
</div></div>
</div>
<p>La bontà di adattamento è migliorata.</p>
<p>Esaminiamo la soluzione standardizzata. Vediamo ora che sono scomparse le due anomalie trovate in precedenza.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">standardizedSolution</span><span class="p">(</span><span class="n">fit2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="dataframe">
<caption>A lavaan.data.frame: 46 × 9</caption>
<thead>
	<tr><th scope=col>lhs</th><th scope=col>op</th><th scope=col>rhs</th><th scope=col>est.std</th><th scope=col>se</th><th scope=col>z</th><th scope=col>pvalue</th><th scope=col>ci.lower</th><th scope=col>ci.upper</th></tr>
	<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><td>copingm </td><td>=~</td><td>x1      </td><td>0.5136919</td><td>0.04268561</td><td>12.034311</td><td>0.000000e+00</td><td> 0.43002967</td><td>0.59735419</td></tr>
	<tr><td>copingm </td><td>=~</td><td>x2      </td><td>0.5149158</td><td>0.04265451</td><td>12.071778</td><td>0.000000e+00</td><td> 0.43131452</td><td>0.59851714</td></tr>
	<tr><td>copingm </td><td>=~</td><td>x3      </td><td>0.5160398</td><td>0.04262607</td><td>12.106202</td><td>0.000000e+00</td><td> 0.43249424</td><td>0.59958536</td></tr>
	<tr><td>copingm </td><td>=~</td><td>x4      </td><td>0.5380264</td><td>0.06212680</td><td> 8.660133</td><td>0.000000e+00</td><td> 0.41626007</td><td>0.65979267</td></tr>
	<tr><td>socialm </td><td>=~</td><td>x4      </td><td>0.4389970</td><td>0.06093489</td><td> 7.204362</td><td>5.830891e-13</td><td> 0.31956680</td><td>0.55842720</td></tr>
	<tr><td>socialm </td><td>=~</td><td>x5      </td><td>0.6318747</td><td>0.03160090</td><td>19.995465</td><td>0.000000e+00</td><td> 0.56993804</td><td>0.69381129</td></tr>
	<tr><td>socialm </td><td>=~</td><td>x6      </td><td>0.7464621</td><td>0.02549441</td><td>29.279444</td><td>0.000000e+00</td><td> 0.69649398</td><td>0.79643023</td></tr>
	<tr><td>socialm </td><td>=~</td><td>x7      </td><td>0.6905804</td><td>0.02849475</td><td>24.235357</td><td>0.000000e+00</td><td> 0.63473172</td><td>0.74642908</td></tr>
	<tr><td>socialm </td><td>=~</td><td>x8      </td><td>0.7308592</td><td>0.02632560</td><td>27.762304</td><td>0.000000e+00</td><td> 0.67926197</td><td>0.78245641</td></tr>
	<tr><td>enhancem</td><td>=~</td><td>x9      </td><td>0.6026163</td><td>0.03856640</td><td>15.625422</td><td>0.000000e+00</td><td> 0.52702753</td><td>0.67820505</td></tr>
	<tr><td>enhancem</td><td>=~</td><td>x10     </td><td>0.5946609</td><td>0.03884764</td><td>15.307516</td><td>0.000000e+00</td><td> 0.51852093</td><td>0.67080088</td></tr>
	<tr><td>enhancem</td><td>=~</td><td>x11     </td><td>0.6649364</td><td>0.03655910</td><td>18.187989</td><td>0.000000e+00</td><td> 0.59328193</td><td>0.73659095</td></tr>
	<tr><td>enhancem</td><td>=~</td><td>x12     </td><td>0.6629023</td><td>0.03661848</td><td>18.102943</td><td>0.000000e+00</td><td> 0.59113140</td><td>0.73467321</td></tr>
	<tr><td>x1      </td><td>~~</td><td>x1      </td><td>0.7361206</td><td>0.04385451</td><td>16.785517</td><td>0.000000e+00</td><td> 0.65016735</td><td>0.82207386</td></tr>
	<tr><td>x2      </td><td>~~</td><td>x2      </td><td>0.7348617</td><td>0.04392697</td><td>16.729169</td><td>0.000000e+00</td><td> 0.64876641</td><td>0.82095697</td></tr>
	<tr><td>x3      </td><td>~~</td><td>x3      </td><td>0.7337029</td><td>0.04399350</td><td>16.677531</td><td>0.000000e+00</td><td> 0.64747725</td><td>0.81992859</td></tr>
	<tr><td>x4      </td><td>~~</td><td>x4      </td><td>0.2298436</td><td>0.03653228</td><td> 6.291520</td><td>3.143723e-10</td><td> 0.15824160</td><td>0.30144550</td></tr>
	<tr><td>x5      </td><td>~~</td><td>x5      </td><td>0.6007344</td><td>0.03993562</td><td>15.042573</td><td>0.000000e+00</td><td> 0.52246204</td><td>0.67900677</td></tr>
	<tr><td>x6      </td><td>~~</td><td>x6      </td><td>0.4427943</td><td>0.03806122</td><td>11.633740</td><td>0.000000e+00</td><td> 0.36819571</td><td>0.51739294</td></tr>
	<tr><td>x7      </td><td>~~</td><td>x7      </td><td>0.5230987</td><td>0.03935583</td><td>13.291518</td><td>0.000000e+00</td><td> 0.44596271</td><td>0.60023472</td></tr>
	<tr><td>x8      </td><td>~~</td><td>x8      </td><td>0.4658448</td><td>0.03848061</td><td>12.105964</td><td>0.000000e+00</td><td> 0.39042424</td><td>0.54126545</td></tr>
	<tr><td>x9      </td><td>~~</td><td>x9      </td><td>0.6368536</td><td>0.04648148</td><td>13.701233</td><td>0.000000e+00</td><td> 0.54575157</td><td>0.72795564</td></tr>
	<tr><td>x10     </td><td>~~</td><td>x10     </td><td>0.6463784</td><td>0.04620235</td><td>13.990164</td><td>0.000000e+00</td><td> 0.55582348</td><td>0.73693335</td></tr>
	<tr><td>x11     </td><td>~~</td><td>x11     </td><td>0.5578595</td><td>0.04861895</td><td>11.474117</td><td>0.000000e+00</td><td> 0.46256814</td><td>0.65315093</td></tr>
	<tr><td>x12     </td><td>~~</td><td>x12     </td><td>0.5605605</td><td>0.04854895</td><td>11.546295</td><td>0.000000e+00</td><td> 0.46540634</td><td>0.65571474</td></tr>
	<tr><td>copingm </td><td>~~</td><td>copingm </td><td>1.0000000</td><td>0.00000000</td><td>       NA</td><td>          NA</td><td> 1.00000000</td><td>1.00000000</td></tr>
	<tr><td>socialm </td><td>~~</td><td>socialm </td><td>1.0000000</td><td>0.00000000</td><td>       NA</td><td>          NA</td><td> 1.00000000</td><td>1.00000000</td></tr>
	<tr><td>enhancem</td><td>~~</td><td>enhancem</td><td>1.0000000</td><td>0.00000000</td><td>       NA</td><td>          NA</td><td> 1.00000000</td><td>1.00000000</td></tr>
	<tr><td>copingm </td><td>~~</td><td>socialm </td><td>0.6096010</td><td>0.05673806</td><td>10.744128</td><td>0.000000e+00</td><td> 0.49839643</td><td>0.72080553</td></tr>
	<tr><td>copingm </td><td>~~</td><td>enhancem</td><td>0.3499566</td><td>0.05867859</td><td> 5.963957</td><td>2.462012e-09</td><td> 0.23494868</td><td>0.46496453</td></tr>
	<tr><td>socialm </td><td>~~</td><td>enhancem</td><td>0.2645008</td><td>0.05517209</td><td> 4.794105</td><td>1.634027e-06</td><td> 0.15636549</td><td>0.37263611</td></tr>
	<tr><td>x1      </td><td>~1</td><td>        </td><td>0.0000000</td><td>0.04472136</td><td> 0.000000</td><td>1.000000e+00</td><td>-0.08765225</td><td>0.08765225</td></tr>
	<tr><td>x2      </td><td>~1</td><td>        </td><td>0.0000000</td><td>0.04472136</td><td> 0.000000</td><td>1.000000e+00</td><td>-0.08765225</td><td>0.08765225</td></tr>
	<tr><td>x3      </td><td>~1</td><td>        </td><td>0.0000000</td><td>0.04472136</td><td> 0.000000</td><td>1.000000e+00</td><td>-0.08765225</td><td>0.08765225</td></tr>
	<tr><td>x4      </td><td>~1</td><td>        </td><td>0.0000000</td><td>0.04472136</td><td> 0.000000</td><td>1.000000e+00</td><td>-0.08765225</td><td>0.08765225</td></tr>
	<tr><td>x5      </td><td>~1</td><td>        </td><td>0.0000000</td><td>0.04472136</td><td> 0.000000</td><td>1.000000e+00</td><td>-0.08765225</td><td>0.08765225</td></tr>
	<tr><td>x6      </td><td>~1</td><td>        </td><td>0.0000000</td><td>0.04472136</td><td> 0.000000</td><td>1.000000e+00</td><td>-0.08765225</td><td>0.08765225</td></tr>
	<tr><td>x7      </td><td>~1</td><td>        </td><td>0.0000000</td><td>0.04472136</td><td> 0.000000</td><td>1.000000e+00</td><td>-0.08765225</td><td>0.08765225</td></tr>
	<tr><td>x8      </td><td>~1</td><td>        </td><td>0.0000000</td><td>0.04472136</td><td> 0.000000</td><td>1.000000e+00</td><td>-0.08765225</td><td>0.08765225</td></tr>
	<tr><td>x9      </td><td>~1</td><td>        </td><td>0.0000000</td><td>0.04472136</td><td> 0.000000</td><td>1.000000e+00</td><td>-0.08765225</td><td>0.08765225</td></tr>
	<tr><td>x10     </td><td>~1</td><td>        </td><td>0.0000000</td><td>0.04472136</td><td> 0.000000</td><td>1.000000e+00</td><td>-0.08765225</td><td>0.08765225</td></tr>
	<tr><td>x11     </td><td>~1</td><td>        </td><td>0.0000000</td><td>0.04472136</td><td> 0.000000</td><td>1.000000e+00</td><td>-0.08765225</td><td>0.08765225</td></tr>
	<tr><td>x12     </td><td>~1</td><td>        </td><td>0.0000000</td><td>0.04472136</td><td> 0.000000</td><td>1.000000e+00</td><td>-0.08765225</td><td>0.08765225</td></tr>
	<tr><td>copingm </td><td>~1</td><td>        </td><td>0.0000000</td><td>0.00000000</td><td>       NA</td><td>          NA</td><td> 0.00000000</td><td>0.00000000</td></tr>
	<tr><td>socialm </td><td>~1</td><td>        </td><td>0.0000000</td><td>0.00000000</td><td>       NA</td><td>          NA</td><td> 0.00000000</td><td>0.00000000</td></tr>
	<tr><td>enhancem</td><td>~1</td><td>        </td><td>0.0000000</td><td>0.00000000</td><td>       NA</td><td>          NA</td><td> 0.00000000</td><td>0.00000000</td></tr>
</tbody>
</table>
</div></div>
</div>
<p>Esaminando i MI, notiamo che il modello potrebbe migliorare se introduciamo una correlazione tra le specificità <code class="docutils literal notranslate"><span class="pre">x11</span></code> e <code class="docutils literal notranslate"><span class="pre">x12</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">modindices</span><span class="p">(</span><span class="n">fit2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="dataframe">
<caption>A lavaan.data.frame: 89 × 8</caption>
<thead>
	<tr><th></th><th scope=col>lhs</th><th scope=col>op</th><th scope=col>rhs</th><th scope=col>mi</th><th scope=col>epc</th><th scope=col>sepc.lv</th><th scope=col>sepc.all</th><th scope=col>sepc.nox</th></tr>
	<tr><th></th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><th scope=row>47</th><td>copingm </td><td>=~</td><td>x5 </td><td>0.075879281</td><td> 0.032464745</td><td> 0.034320003</td><td> 0.019858025</td><td> 0.019858025</td></tr>
	<tr><th scope=row>48</th><td>copingm </td><td>=~</td><td>x6 </td><td>1.412911873</td><td> 0.143137105</td><td> 0.151316941</td><td> 0.085575383</td><td> 0.085575383</td></tr>
	<tr><th scope=row>49</th><td>copingm </td><td>=~</td><td>x7 </td><td>0.244623644</td><td> 0.083197038</td><td> 0.087951488</td><td> 0.035357264</td><td> 0.035357264</td></tr>
	<tr><th scope=row>50</th><td>copingm </td><td>=~</td><td>x8 </td><td>3.668026217</td><td>-0.294652924</td><td>-0.311491413</td><td>-0.137358226</td><td>-0.137358226</td></tr>
	<tr><th scope=row>51</th><td>copingm </td><td>=~</td><td>x9 </td><td>0.242920085</td><td> 0.065568420</td><td> 0.069315449</td><td> 0.025889887</td><td> 0.025889887</td></tr>
	<tr><th scope=row>52</th><td>copingm </td><td>=~</td><td>x10</td><td>0.566100546</td><td> 0.065434430</td><td> 0.069173802</td><td> 0.039567476</td><td> 0.039567476</td></tr>
	<tr><th scope=row>53</th><td>copingm </td><td>=~</td><td>x11</td><td>0.119109121</td><td>-0.043934458</td><td>-0.046445174</td><td>-0.018090153</td><td>-0.018090153</td></tr>
	<tr><th scope=row>54</th><td>copingm </td><td>=~</td><td>x12</td><td>0.598292941</td><td>-0.101897430</td><td>-0.107720548</td><td>-0.040537007</td><td>-0.040537007</td></tr>
	<tr><th scope=row>55</th><td>socialm </td><td>=~</td><td>x1 </td><td>1.947767101</td><td>-0.395605353</td><td>-0.244629140</td><td>-0.118870915</td><td>-0.118870915</td></tr>
	<tr><th scope=row>56</th><td>socialm </td><td>=~</td><td>x2 </td><td>0.718049453</td><td> 0.177418638</td><td> 0.109709761</td><td> 0.072249732</td><td> 0.072249732</td></tr>
	<tr><th scope=row>57</th><td>socialm </td><td>=~</td><td>x3 </td><td>0.297752655</td><td> 0.144452800</td><td> 0.089324788</td><td> 0.046569913</td><td> 0.046569913</td></tr>
	<tr><th scope=row>58</th><td>socialm </td><td>=~</td><td>x9 </td><td>0.315538712</td><td> 0.114063271</td><td> 0.070532918</td><td> 0.026344621</td><td> 0.026344621</td></tr>
	<tr><th scope=row>59</th><td>socialm </td><td>=~</td><td>x10</td><td>3.169241286</td><td> 0.236374679</td><td> 0.146166208</td><td> 0.083607200</td><td> 0.083607200</td></tr>
	<tr><th scope=row>60</th><td>socialm </td><td>=~</td><td>x11</td><td>4.927007444</td><td>-0.430218894</td><td>-0.266032998</td><td>-0.103618466</td><td>-0.103618466</td></tr>
	<tr><th scope=row>61</th><td>socialm </td><td>=~</td><td>x12</td><td>0.017124127</td><td> 0.026249184</td><td> 0.016231619</td><td> 0.006108224</td><td> 0.006108224</td></tr>
	<tr><th scope=row>62</th><td>enhancem</td><td>=~</td><td>x1 </td><td>0.313590008</td><td> 0.039551624</td><td> 0.063812400</td><td> 0.031007910</td><td> 0.031007910</td></tr>
	<tr><th scope=row>63</th><td>enhancem</td><td>=~</td><td>x2 </td><td>0.002792433</td><td> 0.002753742</td><td> 0.004442873</td><td> 0.002925869</td><td> 0.002925869</td></tr>
	<tr><th scope=row>64</th><td>enhancem</td><td>=~</td><td>x3 </td><td>0.036819178</td><td>-0.012629957</td><td>-0.020377113</td><td>-0.010623707</td><td>-0.010623707</td></tr>
	<tr><th scope=row>65</th><td>enhancem</td><td>=~</td><td>x4 </td><td>0.106389675</td><td>-0.012820452</td><td>-0.020684455</td><td>-0.014684515</td><td>-0.014684515</td></tr>
	<tr><th scope=row>66</th><td>enhancem</td><td>=~</td><td>x5 </td><td>0.464252320</td><td>-0.034063087</td><td>-0.054957221</td><td>-0.031799002</td><td>-0.031799002</td></tr>
	<tr><th scope=row>67</th><td>enhancem</td><td>=~</td><td>x6 </td><td>2.703472740</td><td> 0.079190634</td><td> 0.127765789</td><td> 0.072256327</td><td> 0.072256327</td></tr>
	<tr><th scope=row>68</th><td>enhancem</td><td>=~</td><td>x7 </td><td>0.466547100</td><td>-0.047570946</td><td>-0.076750737</td><td>-0.030854464</td><td>-0.030854464</td></tr>
	<tr><th scope=row>69</th><td>enhancem</td><td>=~</td><td>x8 </td><td>0.094615783</td><td>-0.019129220</td><td>-0.030862991</td><td>-0.013609639</td><td>-0.013609639</td></tr>
	<tr><th scope=row>70</th><td>x1      </td><td>~~</td><td>x2 </td><td>1.966143329</td><td> 0.187287831</td><td> 0.187287831</td><td> 0.081487437</td><td> 0.081487437</td></tr>
	<tr><th scope=row>71</th><td>x1      </td><td>~~</td><td>x3 </td><td>2.042378382</td><td>-0.241327807</td><td>-0.241327807</td><td>-0.083190475</td><td>-0.083190475</td></tr>
	<tr><th scope=row>72</th><td>x1      </td><td>~~</td><td>x4 </td><td>0.775485559</td><td> 0.098280683</td><td> 0.098280683</td><td> 0.082425285</td><td> 0.082425285</td></tr>
	<tr><th scope=row>73</th><td>x1      </td><td>~~</td><td>x5 </td><td>0.237902661</td><td>-0.057632489</td><td>-0.057632489</td><td>-0.024367321</td><td>-0.024367321</td></tr>
	<tr><th scope=row>74</th><td>x1      </td><td>~~</td><td>x6 </td><td>0.186730495</td><td>-0.047855957</td><td>-0.047855957</td><td>-0.023035053</td><td>-0.023035053</td></tr>
	<tr><th scope=row>75</th><td>x1      </td><td>~~</td><td>x7 </td><td>0.018723943</td><td>-0.022287044</td><td>-0.022287044</td><td>-0.007015991</td><td>-0.007015991</td></tr>
	<tr><th scope=row>76</th><td>x1      </td><td>~~</td><td>x8 </td><td>0.365508385</td><td>-0.086948141</td><td>-0.086948141</td><td>-0.031815678</td><td>-0.031815678</td></tr>
	<tr><th scope=row>⋮</th><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td></tr>
	<tr><th scope=row>106</th><td>x4 </td><td>~~</td><td>x11</td><td> 1.312840720</td><td>-0.101878937</td><td>-0.101878937</td><td>-0.078672506</td><td>-0.078672506</td></tr>
	<tr><th scope=row>107</th><td>x4 </td><td>~~</td><td>x12</td><td> 0.321917677</td><td> 0.052251350</td><td> 0.052251350</td><td> 0.038890072</td><td> 0.038890072</td></tr>
	<tr><th scope=row>108</th><td>x5 </td><td>~~</td><td>x6 </td><td> 0.503619921</td><td> 0.066410080</td><td> 0.066410080</td><td> 0.042134879</td><td> 0.042134879</td></tr>
	<tr><th scope=row>109</th><td>x5 </td><td>~~</td><td>x7 </td><td> 0.262162750</td><td>-0.068368943</td><td>-0.068368943</td><td>-0.028369388</td><td>-0.028369388</td></tr>
	<tr><th scope=row>110</th><td>x5 </td><td>~~</td><td>x8 </td><td> 0.004247385</td><td> 0.007840557</td><td> 0.007840557</td><td> 0.003781659</td><td> 0.003781659</td></tr>
	<tr><th scope=row>111</th><td>x5 </td><td>~~</td><td>x9 </td><td> 0.849725569</td><td> 0.135425450</td><td> 0.135425450</td><td> 0.047318183</td><td> 0.047318183</td></tr>
	<tr><th scope=row>112</th><td>x5 </td><td>~~</td><td>x10</td><td> 0.288139536</td><td> 0.051689288</td><td> 0.051689288</td><td> 0.027453727</td><td> 0.027453727</td></tr>
	<tr><th scope=row>113</th><td>x5 </td><td>~~</td><td>x11</td><td> 1.018598997</td><td>-0.138036785</td><td>-0.138036785</td><td>-0.053738004</td><td>-0.053738004</td></tr>
	<tr><th scope=row>114</th><td>x5 </td><td>~~</td><td>x12</td><td> 1.223895837</td><td>-0.156755686</td><td>-0.156755686</td><td>-0.058818324</td><td>-0.058818324</td></tr>
	<tr><th scope=row>115</th><td>x6 </td><td>~~</td><td>x7 </td><td> 2.404267265</td><td>-0.208536197</td><td>-0.208536197</td><td>-0.098511143</td><td>-0.098511143</td></tr>
	<tr><th scope=row>116</th><td>x6 </td><td>~~</td><td>x8 </td><td> 0.033517700</td><td> 0.022710567</td><td> 0.022710567</td><td> 0.012470280</td><td> 0.012470280</td></tr>
	<tr><th scope=row>117</th><td>x6 </td><td>~~</td><td>x9 </td><td> 0.978424122</td><td>-0.135107947</td><td>-0.135107947</td><td>-0.053742946</td><td>-0.053742946</td></tr>
	<tr><th scope=row>118</th><td>x6 </td><td>~~</td><td>x10</td><td> 0.523836252</td><td> 0.064789637</td><td> 0.064789637</td><td> 0.039175910</td><td> 0.039175910</td></tr>
	<tr><th scope=row>119</th><td>x6 </td><td>~~</td><td>x11</td><td> 0.340744066</td><td> 0.074312372</td><td> 0.074312372</td><td> 0.032935224</td><td> 0.032935224</td></tr>
	<tr><th scope=row>120</th><td>x6 </td><td>~~</td><td>x12</td><td> 1.519932821</td><td> 0.162590927</td><td> 0.162590927</td><td> 0.069454190</td><td> 0.069454190</td></tr>
	<tr><th scope=row>121</th><td>x7 </td><td>~~</td><td>x8 </td><td> 1.170700334</td><td> 0.186223650</td><td> 0.186223650</td><td> 0.066875403</td><td> 0.066875403</td></tr>
	<tr><th scope=row>122</th><td>x7 </td><td>~~</td><td>x9 </td><td> 0.019578625</td><td>-0.028247666</td><td>-0.028247666</td><td>-0.007348632</td><td>-0.007348632</td></tr>
	<tr><th scope=row>123</th><td>x7 </td><td>~~</td><td>x10</td><td> 1.593217056</td><td>-0.167012340</td><td>-0.167012340</td><td>-0.066045841</td><td>-0.066045841</td></tr>
	<tr><th scope=row>124</th><td>x7 </td><td>~~</td><td>x11</td><td> 0.175352432</td><td>-0.078735934</td><td>-0.078735934</td><td>-0.022822112</td><td>-0.022822112</td></tr>
	<tr><th scope=row>125</th><td>x7 </td><td>~~</td><td>x12</td><td> 0.585734957</td><td> 0.149079342</td><td> 0.149079342</td><td> 0.041648846</td><td> 0.041648846</td></tr>
	<tr><th scope=row>126</th><td>x8 </td><td>~~</td><td>x9 </td><td> 1.807601677</td><td> 0.238879668</td><td> 0.238879668</td><td> 0.072234959</td><td> 0.072234959</td></tr>
	<tr><th scope=row>127</th><td>x8 </td><td>~~</td><td>x10</td><td> 1.267267918</td><td> 0.131087814</td><td> 0.131087814</td><td> 0.060256451</td><td> 0.060256451</td></tr>
	<tr><th scope=row>128</th><td>x8 </td><td>~~</td><td>x11</td><td> 1.790880844</td><td>-0.221558423</td><td>-0.221558423</td><td>-0.074647528</td><td>-0.074647528</td></tr>
	<tr><th scope=row>129</th><td>x8 </td><td>~~</td><td>x12</td><td> 0.594705739</td><td>-0.132265750</td><td>-0.132265750</td><td>-0.042951389</td><td>-0.042951389</td></tr>
	<tr><th scope=row>130</th><td>x9 </td><td>~~</td><td>x10</td><td>20.103443085</td><td> 0.864153027</td><td> 0.864153027</td><td> 0.287755897</td><td> 0.287755897</td></tr>
	<tr><th scope=row>131</th><td>x9 </td><td>~~</td><td>x11</td><td> 3.657937856</td><td>-0.581931484</td><td>-0.581931484</td><td>-0.142033691</td><td>-0.142033691</td></tr>
	<tr><th scope=row>132</th><td>x9 </td><td>~~</td><td>x12</td><td> 7.229240234</td><td>-0.844665516</td><td>-0.844665516</td><td>-0.198704148</td><td>-0.198704148</td></tr>
	<tr><th scope=row>133</th><td>x10</td><td>~~</td><td>x11</td><td> 7.616620851</td><td>-0.542923777</td><td>-0.542923777</td><td>-0.201433342</td><td>-0.201433342</td></tr>
	<tr><th scope=row>134</th><td>x10</td><td>~~</td><td>x12</td><td> 4.511579657</td><td>-0.431468191</td><td>-0.431468191</td><td>-0.154292185</td><td>-0.154292185</td></tr>
	<tr><th scope=row>135</th><td>x11</td><td>~~</td><td>x12</td><td>26.070575353</td><td> 1.680100700</td><td> 1.680100700</td><td> 0.440368656</td><td> 0.440368656</td></tr>
</tbody>
</table>
</div></div>
</div>
<p>Il nuovo modello diventa dunque il seguente.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">model3</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="s">&#39;</span>
<span class="s">  copingm  =~ x1 + x2 + x3 + x4</span>
<span class="s">  socialm  =~ x4 + x5 + x6 + x7 + x8</span>
<span class="s">  enhancem =~ x9 + x10 + x11 + x12</span>
<span class="s">  x11 ~~ x12</span>
<span class="s">&#39;</span>
</pre></div>
</div>
</div>
</div>
<p>Adattiamo il modello.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">fit3</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">cfa</span><span class="p">(</span>
<span class="w">  </span><span class="n">model3</span><span class="p">,</span><span class="w"> </span>
<span class="w">  </span><span class="n">sample.cov</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">covs</span><span class="p">,</span><span class="w"> </span>
<span class="w">  </span><span class="n">sample.nobs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">500</span><span class="p">,</span><span class="w"> </span>
<span class="w">  </span><span class="n">mimic</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;mplus&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Warning message in lavaan::lavaan(model = model3, sample.cov = covs, sample.nobs = 500, :
“lavaan WARNING:
    sample.mean= argument is missing, but model contains
    mean/intercept parameters.”
</pre></div>
</div>
</div>
</div>
<p>Un test basato sul rapporto di verosimiglianze conferma che il miglioramento di adattamento è sostanziale.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">lavTestLRT</span><span class="p">(</span><span class="n">fit2</span><span class="p">,</span><span class="w"> </span><span class="n">fit3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="dataframe">
<caption>A anova: 2 × 8</caption>
<thead>
	<tr><th></th><th scope=col>Df</th><th scope=col>AIC</th><th scope=col>BIC</th><th scope=col>Chisq</th><th scope=col>Chisq diff</th><th scope=col>RMSEA</th><th scope=col>Df diff</th><th scope=col>Pr(&gt;Chisq)</th></tr>
	<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><th scope=row>fit3</th><td>49</td><td>23934.34</td><td>24107.14</td><td>44.95535</td><td>      NA</td><td>       NA</td><td>NA</td><td>          NA</td></tr>
	<tr><th scope=row>fit2</th><td>50</td><td>23956.83</td><td>24125.41</td><td>69.44357</td><td>24.48823</td><td>0.2167405</td><td> 1</td><td>7.476528e-07</td></tr>
</tbody>
</table>
</div></div>
</div>
<p>Esaminiamo gli indici di bontà di adattamento.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">out</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">summary</span><span class="p">(</span><span class="n">fit3</span><span class="p">,</span><span class="w"> </span><span class="n">fit.measures</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>lavaan 0.6.15 ended normally after 61 iterations

  Estimator                                         ML
  Optimization method                           NLMINB
  Number of model parameters                        41

  Number of observations                           500

Model Test User Model:
                                                      
  Test statistic                                44.955
  Degrees of freedom                                49
  P-value (Chi-square)                           0.638

Model Test Baseline Model:

  Test statistic                              1664.026
  Degrees of freedom                                66
  P-value                                        0.000

User Model versus Baseline Model:

  Comparative Fit Index (CFI)                    1.000
  Tucker-Lewis Index (TLI)                       1.003

Loglikelihood and Information Criteria:

  Loglikelihood user model (H0)             -11926.170
  Loglikelihood unrestricted model (H1)     -11903.692
                                                      
  Akaike (AIC)                               23934.339
  Bayesian (BIC)                             24107.138
  Sample-size adjusted Bayesian (SABIC)      23977.002

Root Mean Square Error of Approximation:

  RMSEA                                          0.000
  90 Percent confidence interval - lower         0.000
  90 Percent confidence interval - upper         0.025
  P-value H_0: RMSEA &lt;= 0.050                    1.000
  P-value H_0: RMSEA &gt;= 0.080                    0.000

Standardized Root Mean Square Residual:

  SRMR                                           0.023

Parameter Estimates:

  Standard errors                             Standard
  Information                                 Expected
  Information saturated (h1) model          Structured

Latent Variables:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  copingm =~                                          
    x1                1.000                           
    x2                0.740    0.094    7.909    0.000
    x3                0.933    0.118    7.903    0.000
    x4                0.719    0.118    6.070    0.000
  socialm =~                                          
    x4                1.000                           
    x5                1.771    0.273    6.485    0.000
    x6                2.141    0.319    6.703    0.000
    x7                2.784    0.421    6.611    0.000
    x8                2.689    0.402    6.681    0.000
  enhancem =~                                         
    x9                1.000                           
    x10               0.648    0.070    9.293    0.000
    x11               0.776    0.093    8.340    0.000
    x12               0.802    0.096    8.327    0.000

Covariances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
 .x11 ~~                                              
   .x12               1.460    0.300    4.873    0.000
  copingm ~~                                          
    socialm           0.398    0.071    5.603    0.000
    enhancem          0.669    0.145    4.613    0.000
  socialm ~~                                          
    enhancem          0.320    0.084    3.783    0.000

Intercepts:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .x1                0.000    0.092    0.000    1.000
   .x2                0.000    0.068    0.000    1.000
   .x3                0.000    0.086    0.000    1.000
   .x4                0.000    0.063    0.000    1.000
   .x5                0.000    0.077    0.000    1.000
   .x6                0.000    0.079    0.000    1.000
   .x7                0.000    0.111    0.000    1.000
   .x8                0.000    0.101    0.000    1.000
   .x9                0.000    0.120    0.000    1.000
   .x10               0.000    0.078    0.000    1.000
   .x11               0.000    0.115    0.000    1.000
   .x12               0.000    0.119    0.000    1.000
    copingm           0.000                           
    socialm           0.000                           
    enhancem          0.000                           

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .x1                3.117    0.230   13.546    0.000
   .x2                1.694    0.125   13.527    0.000
   .x3                2.705    0.200   13.536    0.000
   .x4                0.454    0.070    6.502    0.000
   .x5                1.794    0.130   13.835    0.000
   .x6                1.384    0.115   12.015    0.000
   .x7                3.240    0.248   13.089    0.000
   .x8                2.393    0.194   12.352    0.000
   .x9                3.958    0.400    9.895    0.000
   .x10               1.710    0.170   10.063    0.000
   .x11               4.657    0.371   12.545    0.000
   .x12               4.997    0.398   12.561    0.000
    copingm           1.118    0.217    5.158    0.000
    socialm           0.380    0.110    3.469    0.001
    enhancem          3.210    0.490    6.550    0.000
</pre></div>
</div>
</div>
</div>
<p>Gli indici di fit sono migliorati.</p>
<p>Esaminiamo la soluzione standardizzata.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">standardizedSolution</span><span class="p">(</span><span class="n">fit3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="dataframe">
<caption>A lavaan.data.frame: 47 × 9</caption>
<thead>
	<tr><th scope=col>lhs</th><th scope=col>op</th><th scope=col>rhs</th><th scope=col>est.std</th><th scope=col>se</th><th scope=col>z</th><th scope=col>pvalue</th><th scope=col>ci.lower</th><th scope=col>ci.upper</th></tr>
	<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><td>copingm </td><td>=~</td><td>x1      </td><td>0.5137373</td><td>0.04275270</td><td>12.016486</td><td>0.000000e+00</td><td> 0.42994349</td><td>0.59753101</td></tr>
	<tr><td>copingm </td><td>=~</td><td>x2      </td><td>0.5150194</td><td>0.04272080</td><td>12.055473</td><td>0.000000e+00</td><td> 0.43128819</td><td>0.59875065</td></tr>
	<tr><td>copingm </td><td>=~</td><td>x3      </td><td>0.5144101</td><td>0.04273594</td><td>12.036943</td><td>0.000000e+00</td><td> 0.43064919</td><td>0.59817100</td></tr>
	<tr><td>copingm </td><td>=~</td><td>x4      </td><td>0.5396994</td><td>0.06268938</td><td> 8.609105</td><td>0.000000e+00</td><td> 0.41683052</td><td>0.66256838</td></tr>
	<tr><td>socialm </td><td>=~</td><td>x4      </td><td>0.4377501</td><td>0.06140696</td><td> 7.128672</td><td>1.013412e-12</td><td> 0.31739467</td><td>0.55810553</td></tr>
	<tr><td>socialm </td><td>=~</td><td>x5      </td><td>0.6319500</td><td>0.03159184</td><td>20.003584</td><td>0.000000e+00</td><td> 0.57003112</td><td>0.69386884</td></tr>
	<tr><td>socialm </td><td>=~</td><td>x6      </td><td>0.7464930</td><td>0.02548552</td><td>29.290865</td><td>0.000000e+00</td><td> 0.69654231</td><td>0.79644372</td></tr>
	<tr><td>socialm </td><td>=~</td><td>x7      </td><td>0.6901567</td><td>0.02851159</td><td>24.206176</td><td>0.000000e+00</td><td> 0.63427496</td><td>0.74603836</td></tr>
	<tr><td>socialm </td><td>=~</td><td>x8      </td><td>0.7311852</td><td>0.02630130</td><td>27.800344</td><td>0.000000e+00</td><td> 0.67963558</td><td>0.78273478</td></tr>
	<tr><td>enhancem</td><td>=~</td><td>x9      </td><td>0.6691959</td><td>0.04083337</td><td>16.388454</td><td>0.000000e+00</td><td> 0.58916395</td><td>0.74922784</td></tr>
	<tr><td>enhancem</td><td>=~</td><td>x10     </td><td>0.6637281</td><td>0.04086182</td><td>16.243234</td><td>0.000000e+00</td><td> 0.58364045</td><td>0.74381585</td></tr>
	<tr><td>enhancem</td><td>=~</td><td>x11     </td><td>0.5418274</td><td>0.04470362</td><td>12.120436</td><td>0.000000e+00</td><td> 0.45420990</td><td>0.62944488</td></tr>
	<tr><td>enhancem</td><td>=~</td><td>x12     </td><td>0.5407209</td><td>0.04474879</td><td>12.083474</td><td>0.000000e+00</td><td> 0.45301484</td><td>0.62842687</td></tr>
	<tr><td>x11     </td><td>~~</td><td>x12     </td><td>0.3027101</td><td>0.04964764</td><td> 6.097169</td><td>1.079635e-09</td><td> 0.20540247</td><td>0.40001766</td></tr>
	<tr><td>x1      </td><td>~~</td><td>x1      </td><td>0.7360740</td><td>0.04392731</td><td>16.756638</td><td>0.000000e+00</td><td> 0.64997809</td><td>0.82216998</td></tr>
	<tr><td>x2      </td><td>~~</td><td>x2      </td><td>0.7347550</td><td>0.04400408</td><td>16.697428</td><td>0.000000e+00</td><td> 0.64850858</td><td>0.82100142</td></tr>
	<tr><td>x3      </td><td>~~</td><td>x3      </td><td>0.7353823</td><td>0.04396760</td><td>16.725549</td><td>0.000000e+00</td><td> 0.64920734</td><td>0.82155717</td></tr>
	<tr><td>x4      </td><td>~~</td><td>x4      </td><td>0.2288915</td><td>0.03678071</td><td> 6.223138</td><td>4.873071e-10</td><td> 0.15680259</td><td>0.30098033</td></tr>
	<tr><td>x5      </td><td>~~</td><td>x5      </td><td>0.6006392</td><td>0.03992892</td><td>15.042710</td><td>0.000000e+00</td><td> 0.52237997</td><td>0.67889848</td></tr>
	<tr><td>x6      </td><td>~~</td><td>x6      </td><td>0.4427482</td><td>0.03804953</td><td>11.636101</td><td>0.000000e+00</td><td> 0.36817247</td><td>0.51732388</td></tr>
	<tr><td>x7      </td><td>~~</td><td>x7      </td><td>0.5236838</td><td>0.03935493</td><td>13.306687</td><td>0.000000e+00</td><td> 0.44654953</td><td>0.60081804</td></tr>
	<tr><td>x8      </td><td>~~</td><td>x8      </td><td>0.4653682</td><td>0.03846224</td><td>12.099353</td><td>0.000000e+00</td><td> 0.38998362</td><td>0.54075284</td></tr>
	<tr><td>x9      </td><td>~~</td><td>x9      </td><td>0.5521769</td><td>0.05465105</td><td>10.103682</td><td>0.000000e+00</td><td> 0.44506275</td><td>0.65929095</td></tr>
	<tr><td>x10     </td><td>~~</td><td>x10     </td><td>0.5594649</td><td>0.05424229</td><td>10.314185</td><td>0.000000e+00</td><td> 0.45315202</td><td>0.66577787</td></tr>
	<tr><td>x11     </td><td>~~</td><td>x11     </td><td>0.7064231</td><td>0.04844330</td><td>14.582474</td><td>0.000000e+00</td><td> 0.61147596</td><td>0.80137019</td></tr>
	<tr><td>x12     </td><td>~~</td><td>x12     </td><td>0.7076210</td><td>0.04839321</td><td>14.622320</td><td>0.000000e+00</td><td> 0.61277201</td><td>0.80246990</td></tr>
	<tr><td>copingm </td><td>~~</td><td>copingm </td><td>1.0000000</td><td>0.00000000</td><td>       NA</td><td>          NA</td><td> 1.00000000</td><td>1.00000000</td></tr>
	<tr><td>socialm </td><td>~~</td><td>socialm </td><td>1.0000000</td><td>0.00000000</td><td>       NA</td><td>          NA</td><td> 1.00000000</td><td>1.00000000</td></tr>
	<tr><td>enhancem</td><td>~~</td><td>enhancem</td><td>1.0000000</td><td>0.00000000</td><td>       NA</td><td>          NA</td><td> 1.00000000</td><td>1.00000000</td></tr>
	<tr><td>copingm </td><td>~~</td><td>socialm </td><td>0.6099548</td><td>0.05682136</td><td>10.734604</td><td>0.000000e+00</td><td> 0.49858697</td><td>0.72132261</td></tr>
	<tr><td>copingm </td><td>~~</td><td>enhancem</td><td>0.3532465</td><td>0.06044471</td><td> 5.844126</td><td>5.092334e-09</td><td> 0.23477709</td><td>0.47171601</td></tr>
	<tr><td>socialm </td><td>~~</td><td>enhancem</td><td>0.2892191</td><td>0.05625324</td><td> 5.141376</td><td>2.727332e-07</td><td> 0.17896475</td><td>0.39947340</td></tr>
	<tr><td>x1      </td><td>~1</td><td>        </td><td>0.0000000</td><td>0.04472136</td><td> 0.000000</td><td>1.000000e+00</td><td>-0.08765225</td><td>0.08765225</td></tr>
	<tr><td>x2      </td><td>~1</td><td>        </td><td>0.0000000</td><td>0.04472136</td><td> 0.000000</td><td>1.000000e+00</td><td>-0.08765225</td><td>0.08765225</td></tr>
	<tr><td>x3      </td><td>~1</td><td>        </td><td>0.0000000</td><td>0.04472136</td><td> 0.000000</td><td>1.000000e+00</td><td>-0.08765225</td><td>0.08765225</td></tr>
	<tr><td>x4      </td><td>~1</td><td>        </td><td>0.0000000</td><td>0.04472136</td><td> 0.000000</td><td>1.000000e+00</td><td>-0.08765225</td><td>0.08765225</td></tr>
	<tr><td>x5      </td><td>~1</td><td>        </td><td>0.0000000</td><td>0.04472136</td><td> 0.000000</td><td>1.000000e+00</td><td>-0.08765225</td><td>0.08765225</td></tr>
	<tr><td>x6      </td><td>~1</td><td>        </td><td>0.0000000</td><td>0.04472136</td><td> 0.000000</td><td>1.000000e+00</td><td>-0.08765225</td><td>0.08765225</td></tr>
	<tr><td>x7      </td><td>~1</td><td>        </td><td>0.0000000</td><td>0.04472136</td><td> 0.000000</td><td>1.000000e+00</td><td>-0.08765225</td><td>0.08765225</td></tr>
	<tr><td>x8      </td><td>~1</td><td>        </td><td>0.0000000</td><td>0.04472136</td><td> 0.000000</td><td>1.000000e+00</td><td>-0.08765225</td><td>0.08765225</td></tr>
	<tr><td>x9      </td><td>~1</td><td>        </td><td>0.0000000</td><td>0.04472136</td><td> 0.000000</td><td>1.000000e+00</td><td>-0.08765225</td><td>0.08765225</td></tr>
	<tr><td>x10     </td><td>~1</td><td>        </td><td>0.0000000</td><td>0.04472136</td><td> 0.000000</td><td>1.000000e+00</td><td>-0.08765225</td><td>0.08765225</td></tr>
	<tr><td>x11     </td><td>~1</td><td>        </td><td>0.0000000</td><td>0.04472136</td><td> 0.000000</td><td>1.000000e+00</td><td>-0.08765225</td><td>0.08765225</td></tr>
	<tr><td>x12     </td><td>~1</td><td>        </td><td>0.0000000</td><td>0.04472136</td><td> 0.000000</td><td>1.000000e+00</td><td>-0.08765225</td><td>0.08765225</td></tr>
	<tr><td>copingm </td><td>~1</td><td>        </td><td>0.0000000</td><td>0.00000000</td><td>       NA</td><td>          NA</td><td> 0.00000000</td><td>0.00000000</td></tr>
	<tr><td>socialm </td><td>~1</td><td>        </td><td>0.0000000</td><td>0.00000000</td><td>       NA</td><td>          NA</td><td> 0.00000000</td><td>0.00000000</td></tr>
	<tr><td>enhancem</td><td>~1</td><td>        </td><td>0.0000000</td><td>0.00000000</td><td>       NA</td><td>          NA</td><td> 0.00000000</td><td>0.00000000</td></tr>
</tbody>
</table>
</div></div>
</div>
<p>Non ci sono ulteriori motivi di preoccupazione.  <span id="id4">Brown [<a class="reference internal" href="z_biblio.html#id32" title="Timothy A Brown. Confirmatory factor analysis for applied research. Guilford publications, 2015.">Bro15</a>]</span> conclude che il modello più adeguato sia <code class="docutils literal notranslate"><span class="pre">model3</span></code>.</p>
<p>Nel caso presente, a mio parare, l’introduzione della correlazione residua tra <code class="docutils literal notranslate"><span class="pre">x11</span></code> e <code class="docutils literal notranslate"><span class="pre">x12</span></code> si sarebbe anche potuta evitare, dato che il modello <code class="docutils literal notranslate"><span class="pre">model3</span></code> (con meno idiosincrasie legate al campione) si era già dimostrato adeguato.</p>
</section>
<section id="saturazione-sul-fattore-sbagliato">
<h2><span class="section-number">15.3. </span>Saturazione sul fattore sbagliato<a class="headerlink" href="#saturazione-sul-fattore-sbagliato" title="Permalink to this headline">#</a></h2>
<p><span id="id5">Brown [<a class="reference internal" href="z_biblio.html#id32" title="Timothy A Brown. Confirmatory factor analysis for applied research. Guilford publications, 2015.">Bro15</a>]</span> considera anche il caso opposto, ovvero quello nel quale il ricercatore ipotizza una saturazione spuria. Per i dati in discussione, si può avere la situazione presente.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">model4</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="s">&#39;</span>
<span class="s">  copingm  =~ x1 + x2 + x3 + x4</span>
<span class="s">  socialm  =~ x4 +x5 + x6 + x7 + x8 + x12</span>
<span class="s">  enhancem =~ x9 + x10 + x11</span>
<span class="s">&#39;</span>
</pre></div>
</div>
</div>
</div>
<p>Adattiamo il modello ai dati.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">fit4</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">cfa</span><span class="p">(</span>
<span class="w">  </span><span class="n">model4</span><span class="p">,</span><span class="w"> </span>
<span class="w">  </span><span class="n">sample.cov</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">covs</span><span class="p">,</span><span class="w"> </span>
<span class="w">  </span><span class="n">sample.nobs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">500</span><span class="p">,</span><span class="w"> </span>
<span class="w">  </span><span class="n">mimic</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;mplus&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Warning message in lavaan::lavaan(model = model4, sample.cov = covs, sample.nobs = 500, :
“lavaan WARNING:
    sample.mean= argument is missing, but model contains
    mean/intercept parameters.”
</pre></div>
</div>
</div>
</div>
<p>Esaminiamo la soluzione ottenuta.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">out</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">summary</span><span class="p">(</span><span class="n">fit4</span><span class="p">,</span><span class="w"> </span><span class="n">fit.measures</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>lavaan 0.6.15 ended normally after 59 iterations

  Estimator                                         ML
  Optimization method                           NLMINB
  Number of model parameters                        40

  Number of observations                           500

Model Test User Model:
                                                      
  Test statistic                               212.717
  Degrees of freedom                                50
  P-value (Chi-square)                           0.000

Model Test Baseline Model:

  Test statistic                              1664.026
  Degrees of freedom                                66
  P-value                                        0.000

User Model versus Baseline Model:

  Comparative Fit Index (CFI)                    0.898
  Tucker-Lewis Index (TLI)                       0.866

Loglikelihood and Information Criteria:

  Loglikelihood user model (H0)             -12010.051
  Loglikelihood unrestricted model (H1)     -11903.692
                                                      
  Akaike (AIC)                               24100.101
  Bayesian (BIC)                             24268.685
  Sample-size adjusted Bayesian (SABIC)      24141.723

Root Mean Square Error of Approximation:

  RMSEA                                          0.081
  90 Percent confidence interval - lower         0.070
  90 Percent confidence interval - upper         0.092
  P-value H_0: RMSEA &lt;= 0.050                    0.000
  P-value H_0: RMSEA &gt;= 0.080                    0.554

Standardized Root Mean Square Residual:

  SRMR                                           0.073

Parameter Estimates:

  Standard errors                             Standard
  Information                                 Expected
  Information saturated (h1) model          Structured

Latent Variables:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  copingm =~                                          
    x1                1.000                           
    x2                0.741    0.093    7.925    0.000
    x3                0.932    0.118    7.906    0.000
    x4                0.699    0.117    5.995    0.000
  socialm =~                                          
    x4                1.000                           
    x5                1.725    0.260    6.634    0.000
    x6                2.098    0.305    6.879    0.000
    x7                2.717    0.401    6.775    0.000
    x8                2.619    0.382    6.848    0.000
    x12               0.900    0.236    3.818    0.000
  enhancem =~                                         
    x9                1.000                           
    x10               0.638    0.076    8.408    0.000
    x11               0.767    0.094    8.153    0.000

Covariances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  copingm ~~                                          
    socialm           0.410    0.072    5.663    0.000
    enhancem          0.661    0.148    4.456    0.000
  socialm ~~                                          
    enhancem          0.347    0.089    3.902    0.000

Intercepts:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .x1                0.000    0.092    0.000    1.000
   .x2                0.000    0.068    0.000    1.000
   .x3                0.000    0.086    0.000    1.000
   .x4                0.000    0.063    0.000    1.000
   .x5                0.000    0.077    0.000    1.000
   .x6                0.000    0.079    0.000    1.000
   .x7                0.000    0.111    0.000    1.000
   .x8                0.000    0.101    0.000    1.000
   .x12               0.000    0.119    0.000    1.000
   .x9                0.000    0.120    0.000    1.000
   .x10               0.000    0.078    0.000    1.000
   .x11               0.000    0.115    0.000    1.000
    copingm           0.000                           
    socialm           0.000                           
    enhancem          0.000                           

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .x1                3.106    0.230   13.478    0.000
   .x2                1.686    0.125   13.449    0.000
   .x3                2.698    0.200   13.477    0.000
   .x4                0.463    0.069    6.719    0.000
   .x5                1.805    0.130   13.886    0.000
   .x6                1.378    0.115   12.022    0.000
   .x7                3.255    0.248   13.143    0.000
   .x8                2.418    0.194   12.455    0.000
   .x12               6.740    0.430   15.673    0.000
   .x9                3.891    0.436    8.933    0.000
   .x10               1.724    0.183    9.435    0.000
   .x11               4.662    0.371   12.579    0.000
    copingm           1.129    0.218    5.170    0.000
    socialm           0.397    0.111    3.566    0.000
    enhancem          3.277    0.524    6.258    0.000
</pre></div>
</div>
</div>
</div>
<p>È chiaro che il modello <code class="docutils literal notranslate"><span class="pre">model4</span></code> è inadeguato. Il problema emerge chiaramente anche esaminando i MI.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">modindices</span><span class="p">(</span><span class="n">fit4</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="dataframe">
<caption>A lavaan.data.frame: 89 × 8</caption>
<thead>
	<tr><th></th><th scope=col>lhs</th><th scope=col>op</th><th scope=col>rhs</th><th scope=col>mi</th><th scope=col>epc</th><th scope=col>sepc.lv</th><th scope=col>sepc.all</th><th scope=col>sepc.nox</th></tr>
	<tr><th></th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><th scope=row>47</th><td>copingm </td><td>=~</td><td>x5 </td><td>  0.09017503</td><td> 0.03562312</td><td> 0.03784791</td><td> 0.021899323</td><td> 0.021899323</td></tr>
	<tr><th scope=row>48</th><td>copingm </td><td>=~</td><td>x6 </td><td>  0.55421214</td><td> 0.09003505</td><td> 0.09565805</td><td> 0.054098226</td><td> 0.054098226</td></tr>
	<tr><th scope=row>49</th><td>copingm </td><td>=~</td><td>x7 </td><td>  0.10746410</td><td> 0.05543532</td><td> 0.05889745</td><td> 0.023677281</td><td> 0.023677281</td></tr>
	<tr><th scope=row>50</th><td>copingm </td><td>=~</td><td>x8 </td><td>  3.91880191</td><td>-0.30573892</td><td>-0.32483339</td><td>-0.143241711</td><td>-0.143241711</td></tr>
	<tr><th scope=row>51</th><td>copingm </td><td>=~</td><td>x12</td><td>  6.10941671</td><td> 0.49879335</td><td> 0.52994476</td><td> 0.199427006</td><td> 0.199427006</td></tr>
	<tr><th scope=row>52</th><td>copingm </td><td>=~</td><td>x9 </td><td>  0.38979797</td><td>-0.09562061</td><td>-0.10159245</td><td>-0.037945578</td><td>-0.037945578</td></tr>
	<tr><th scope=row>53</th><td>copingm </td><td>=~</td><td>x10</td><td>  0.02663662</td><td>-0.01608649</td><td>-0.01709114</td><td>-0.009776150</td><td>-0.009776150</td></tr>
	<tr><th scope=row>54</th><td>copingm </td><td>=~</td><td>x11</td><td>  0.82324384</td><td> 0.12309854</td><td> 0.13078648</td><td> 0.050940643</td><td> 0.050940643</td></tr>
	<tr><th scope=row>55</th><td>socialm </td><td>=~</td><td>x1 </td><td>  1.99011638</td><td>-0.39751600</td><td>-0.25053040</td><td>-0.121738462</td><td>-0.121738462</td></tr>
	<tr><th scope=row>56</th><td>socialm </td><td>=~</td><td>x2 </td><td>  0.63818689</td><td> 0.16639198</td><td> 0.10486685</td><td> 0.069060382</td><td> 0.069060382</td></tr>
	<tr><th scope=row>57</th><td>socialm </td><td>=~</td><td>x3 </td><td>  0.37217899</td><td> 0.16023194</td><td> 0.10098454</td><td> 0.052648813</td><td> 0.052648813</td></tr>
	<tr><th scope=row>58</th><td>socialm </td><td>=~</td><td>x9 </td><td>  0.31477766</td><td>-0.13045181</td><td>-0.08221592</td><td>-0.030708291</td><td>-0.030708291</td></tr>
	<tr><th scope=row>59</th><td>socialm </td><td>=~</td><td>x10</td><td>  1.42307040</td><td> 0.17864053</td><td> 0.11258637</td><td> 0.064399504</td><td> 0.064399504</td></tr>
	<tr><th scope=row>60</th><td>socialm </td><td>=~</td><td>x11</td><td>  0.52007742</td><td>-0.14971313</td><td>-0.09435517</td><td>-0.036750842</td><td>-0.036750842</td></tr>
	<tr><th scope=row>61</th><td>enhancem</td><td>=~</td><td>x1 </td><td>  1.02911333</td><td> 0.06669409</td><td> 0.12072607</td><td> 0.058663564</td><td> 0.058663564</td></tr>
	<tr><th scope=row>62</th><td>enhancem</td><td>=~</td><td>x2 </td><td>  0.23155704</td><td> 0.02334072</td><td> 0.04225013</td><td> 0.027823949</td><td> 0.027823949</td></tr>
	<tr><th scope=row>63</th><td>enhancem</td><td>=~</td><td>x3 </td><td>  0.15333314</td><td>-0.02399418</td><td>-0.04343298</td><td>-0.022644009</td><td>-0.022644009</td></tr>
	<tr><th scope=row>64</th><td>enhancem</td><td>=~</td><td>x4 </td><td>  0.74519462</td><td>-0.03094824</td><td>-0.05602084</td><td>-0.039770883</td><td>-0.039770883</td></tr>
	<tr><th scope=row>65</th><td>enhancem</td><td>=~</td><td>x5 </td><td>  0.34312399</td><td>-0.02781319</td><td>-0.05034594</td><td>-0.029130859</td><td>-0.029130859</td></tr>
	<tr><th scope=row>66</th><td>enhancem</td><td>=~</td><td>x6 </td><td>  0.10312748</td><td> 0.01464260</td><td> 0.02650526</td><td> 0.014989720</td><td> 0.014989720</td></tr>
	<tr><th scope=row>67</th><td>enhancem</td><td>=~</td><td>x7 </td><td>  2.75182606</td><td>-0.10964223</td><td>-0.19846852</td><td>-0.079786055</td><td>-0.079786055</td></tr>
	<tr><th scope=row>68</th><td>enhancem</td><td>=~</td><td>x8 </td><td>  0.12939752</td><td>-0.02122648</td><td>-0.03842304</td><td>-0.016943398</td><td>-0.016943398</td></tr>
	<tr><th scope=row>69</th><td>enhancem</td><td>=~</td><td>x12</td><td>116.78055563</td><td> 0.91578890</td><td> 1.65771216</td><td> 0.623824591</td><td> 0.623824591</td></tr>
	<tr><th scope=row>70</th><td>x1      </td><td>~~</td><td>x2 </td><td>  1.70856301</td><td> 0.17666232</td><td> 0.17666232</td><td> 0.077186338</td><td> 0.077186338</td></tr>
	<tr><th scope=row>71</th><td>x1      </td><td>~~</td><td>x3 </td><td>  2.27308679</td><td>-0.25695039</td><td>-0.25695039</td><td>-0.088754530</td><td>-0.088754530</td></tr>
	<tr><th scope=row>72</th><td>x1      </td><td>~~</td><td>x4 </td><td>  0.85019572</td><td> 0.10317774</td><td> 0.10317774</td><td> 0.086051193</td><td> 0.086051193</td></tr>
	<tr><th scope=row>73</th><td>x1      </td><td>~~</td><td>x5 </td><td>  0.29156144</td><td>-0.06388157</td><td>-0.06388157</td><td>-0.026974801</td><td>-0.026974801</td></tr>
	<tr><th scope=row>74</th><td>x1      </td><td>~~</td><td>x6 </td><td>  0.18845155</td><td>-0.04795089</td><td>-0.04795089</td><td>-0.023176645</td><td>-0.023176645</td></tr>
	<tr><th scope=row>75</th><td>x1      </td><td>~~</td><td>x7 </td><td>  0.02307378</td><td>-0.02475596</td><td>-0.02475596</td><td>-0.007785225</td><td>-0.007785225</td></tr>
	<tr><th scope=row>76</th><td>x1      </td><td>~~</td><td>x8 </td><td>  0.41852446</td><td>-0.09314066</td><td>-0.09314066</td><td>-0.033984772</td><td>-0.033984772</td></tr>
	<tr><th scope=row>⋮</th><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td></tr>
	<tr><th scope=row>106</th><td>x4 </td><td>~~</td><td>x10</td><td>9.138852e-01</td><td> 0.060508783</td><td> 0.060508783</td><td> 0.067730785</td><td> 0.067730785</td></tr>
	<tr><th scope=row>107</th><td>x4 </td><td>~~</td><td>x11</td><td>5.169850e-01</td><td>-0.068349097</td><td>-0.068349097</td><td>-0.046530997</td><td>-0.046530997</td></tr>
	<tr><th scope=row>108</th><td>x5 </td><td>~~</td><td>x6 </td><td>6.113739e-01</td><td> 0.072842975</td><td> 0.072842975</td><td> 0.046181582</td><td> 0.046181582</td></tr>
	<tr><th scope=row>109</th><td>x5 </td><td>~~</td><td>x7 </td><td>1.153198e-01</td><td>-0.045275647</td><td>-0.045275647</td><td>-0.018675970</td><td>-0.018675970</td></tr>
	<tr><th scope=row>110</th><td>x5 </td><td>~~</td><td>x8 </td><td>7.918745e-02</td><td> 0.033755738</td><td> 0.033755738</td><td> 0.016155480</td><td> 0.016155480</td></tr>
	<tr><th scope=row>111</th><td>x5 </td><td>~~</td><td>x12</td><td>3.264796e+00</td><td>-0.302396718</td><td>-0.302396718</td><td>-0.086687525</td><td>-0.086687525</td></tr>
	<tr><th scope=row>112</th><td>x5 </td><td>~~</td><td>x9 </td><td>2.028339e-01</td><td> 0.066152369</td><td> 0.066152369</td><td> 0.024957253</td><td> 0.024957253</td></tr>
	<tr><th scope=row>113</th><td>x5 </td><td>~~</td><td>x10</td><td>4.522542e-04</td><td> 0.002047507</td><td> 0.002047507</td><td> 0.001160392</td><td> 0.001160392</td></tr>
	<tr><th scope=row>114</th><td>x5 </td><td>~~</td><td>x11</td><td>2.311883e+00</td><td>-0.223779997</td><td>-0.223779997</td><td>-0.077133427</td><td>-0.077133427</td></tr>
	<tr><th scope=row>115</th><td>x6 </td><td>~~</td><td>x7 </td><td>2.238702e+00</td><td>-0.199955488</td><td>-0.199955488</td><td>-0.094411109</td><td>-0.094411109</td></tr>
	<tr><th scope=row>116</th><td>x6 </td><td>~~</td><td>x8 </td><td>7.348780e-02</td><td> 0.033339051</td><td> 0.033339051</td><td> 0.018264036</td><td> 0.018264036</td></tr>
	<tr><th scope=row>117</th><td>x6 </td><td>~~</td><td>x12</td><td>4.778443e-01</td><td> 0.108510095</td><td> 0.108510095</td><td> 0.035605815</td><td> 0.035605815</td></tr>
	<tr><th scope=row>118</th><td>x6 </td><td>~~</td><td>x9 </td><td>1.251023e+00</td><td>-0.152816754</td><td>-0.152816754</td><td>-0.065992352</td><td>-0.065992352</td></tr>
	<tr><th scope=row>119</th><td>x6 </td><td>~~</td><td>x10</td><td>7.839316e-01</td><td> 0.079234586</td><td> 0.079234586</td><td> 0.051400286</td><td> 0.051400286</td></tr>
	<tr><th scope=row>120</th><td>x6 </td><td>~~</td><td>x11</td><td>3.703228e-01</td><td> 0.082972291</td><td> 0.082972291</td><td> 0.032736007</td><td> 0.032736007</td></tr>
	<tr><th scope=row>121</th><td>x7 </td><td>~~</td><td>x8 </td><td>1.644356e+00</td><td> 0.219424488</td><td> 0.219424488</td><td> 0.078210665</td><td> 0.078210665</td></tr>
	<tr><th scope=row>122</th><td>x7 </td><td>~~</td><td>x12</td><td>4.328632e-01</td><td>-0.151939667</td><td>-0.151939667</td><td>-0.032438394</td><td>-0.032438394</td></tr>
	<tr><th scope=row>123</th><td>x7 </td><td>~~</td><td>x9 </td><td>5.176871e-03</td><td>-0.014538491</td><td>-0.014538491</td><td>-0.004084880</td><td>-0.004084880</td></tr>
	<tr><th scope=row>124</th><td>x7 </td><td>~~</td><td>x10</td><td>1.836280e+00</td><td>-0.179429687</td><td>-0.179429687</td><td>-0.075732522</td><td>-0.075732522</td></tr>
	<tr><th scope=row>125</th><td>x7 </td><td>~~</td><td>x11</td><td>3.478588e-01</td><td>-0.119232436</td><td>-0.119232436</td><td>-0.030607258</td><td>-0.030607258</td></tr>
	<tr><th scope=row>126</th><td>x8 </td><td>~~</td><td>x12</td><td>2.680163e+00</td><td>-0.334567892</td><td>-0.334567892</td><td>-0.082875501</td><td>-0.082875501</td></tr>
	<tr><th scope=row>127</th><td>x8 </td><td>~~</td><td>x9 </td><td>6.757446e-01</td><td> 0.146530430</td><td> 0.146530430</td><td> 0.047768497</td><td> 0.047768497</td></tr>
	<tr><th scope=row>128</th><td>x8 </td><td>~~</td><td>x10</td><td>3.373531e-01</td><td> 0.067826260</td><td> 0.067826260</td><td> 0.033215418</td><td> 0.033215418</td></tr>
	<tr><th scope=row>129</th><td>x8 </td><td>~~</td><td>x11</td><td>3.436823e+00</td><td>-0.330114547</td><td>-0.330114547</td><td>-0.098321479</td><td>-0.098321479</td></tr>
	<tr><th scope=row>130</th><td>x12</td><td>~~</td><td>x9 </td><td>7.050930e+00</td><td> 0.713217393</td><td> 0.713217393</td><td> 0.139265313</td><td> 0.139265313</td></tr>
	<tr><th scope=row>131</th><td>x12</td><td>~~</td><td>x10</td><td>6.960062e+00</td><td> 0.464746430</td><td> 0.464746430</td><td> 0.136321765</td><td> 0.136321765</td></tr>
	<tr><th scope=row>132</th><td>x12</td><td>~~</td><td>x11</td><td>6.871719e+01</td><td> 2.238104367</td><td> 2.238104367</td><td> 0.399274299</td><td> 0.399274299</td></tr>
	<tr><th scope=row>133</th><td>x9 </td><td>~~</td><td>x10</td><td>8.053654e-02</td><td> 0.137748370</td><td> 0.137748370</td><td> 0.053174994</td><td> 0.053174994</td></tr>
	<tr><th scope=row>134</th><td>x9 </td><td>~~</td><td>x11</td><td>1.656269e-01</td><td> 0.209046823</td><td> 0.209046823</td><td> 0.049080213</td><td> 0.049080213</td></tr>
	<tr><th scope=row>135</th><td>x10</td><td>~~</td><td>x11</td><td>4.234564e-01</td><td>-0.211249628</td><td>-0.211249628</td><td>-0.074505258</td><td>-0.074505258</td></tr>
</tbody>
</table>
</div></div>
</div>
<p>Il MI relativo alla saturazione di <code class="docutils literal notranslate"><span class="pre">x12</span></code> su <code class="docutils literal notranslate"><span class="pre">enhancem</span></code> è uguale a 116.781. Chiaramente, in una revisione del modello, questo problema dovrebbe deve essere affrontato.</p>
</section>
<section id="commenti-e-considerazioni-finali">
<h2><span class="section-number">15.4. </span>Commenti e considerazioni finali {-}<a class="headerlink" href="#commenti-e-considerazioni-finali" title="Permalink to this headline">#</a></h2>
<p>Gli esempi discussi da <span id="id6">Brown [<a class="reference internal" href="z_biblio.html#id32" title="Timothy A Brown. Confirmatory factor analysis for applied research. Guilford publications, 2015.">Bro15</a>]</span> mostrano come l’uso dei MI, insieme all’esame della soluzione fattoriale, possano essere usati dallo psicologo per migliorare il modello che viene proposto.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "r"
        },
        kernelOptions: {
            name: "ir",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'ir'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="300_gof.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">14. </span>Indici di bontà dell’adattamento</p>
      </div>
    </a>
    <a class="right-next"
       href="324_lgm_mixed.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">16. </span>LGM e modelli misti</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#un-numero-di-fattori-troppo-piccolo">15.1. Un numero di fattori troppo piccolo</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#specificazione-errata-delle-relazioni-tra-indicatori-e-fattori-latenti">15.2. Specificazione errata delle relazioni tra indicatori e fattori latenti</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#saturazione-sul-fattore-sbagliato">15.3. Saturazione sul fattore sbagliato</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#commenti-e-considerazioni-finali">15.4. Commenti e considerazioni finali {-}</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            <div class="bd-footer-content__inner">
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Corrado Caudek
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div></div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=12da95d707ffb74b382d"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=12da95d707ffb74b382d"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>